# Mental Rotation Project

Jessica B. Hamrick (jhamrick@berkeley.edu)  
Thomas L. Griffiths (tom_griffiths@berkeley.edu)

## Overview

Given a computational resource--for example, the ability to visualize
an object rotating--how do you best make use of it? This project
explores how mental simulation should be used in the classic
psychological task of determining if two images depict the same object
in different orientations.

## Project Layout

* `config.ini`: configuration variables/parameters/settings
* `analysis/`: IPython notebooks and scripts for running analyses and
  generating figures
* `bin/`: scripts for running simulations, munging data, generating
  stimuli, etc.
* `data/`: human experimental data and model simulation data
* `experiment/`: files necessary to run the Mechanical Turk
  experiment
* `figures/`: figures for slides/papers
* `lib/`: contains the `mental_rotation` Python package, which
  includes the majority of the relevant code
* `man/`: manuscripts, slides, reviews, etc.
* `results/`: results generated by analyses, including `.csv` and
  `.tex` files
* `stimuli/`: stimuli files for use in experiments and simulations
* `tests/`: test suite for the `mental_rotation` Python package

## Stimuli

Stimuli can be found in the `stimuli/` folder, and can be loaded using
the `Stimulus2D` class:

```
from mental_rotation.stimulus import Stimulus2D
stim_path = "stimuli/A/000_120_0.json"
X = Stimulus2D.load(stim_path)
```

## Models

The models for the project are part of the Python package, accessible
from `mental_rotation.model` in Python or `lib/mental_rotation/model/`
in the directory structure.

All models are subclasses of
`mental_rotation.model.BaseModel`. Example code for all the models can
be found in `lib/mental_rotation/analysis/models.ipynb`.

Note: the following documentation may be somewhat out of date

### Gold Standard Model

Located in `lib/mental_rotation/model/gold_standard.py` or
`mental_rotation.model.GoldStandardModel`. The gold standard model
takes a sample from `log_S` at every integer degree (e.g.,
[0, 1, ..., 359, 360]) and uses the trapezoidal rule to estimate the
integral.

```
from mental_rotation.model import GoldStandardModel
gs_model = GoldStandardModel(Xa, Xb)
gs_model.sample()
gs_model.print_stats()
```

### Hill Climbing Model

Located in `lib/mental_rotation/model/hill_climbing.py` or
`mental_rotation.model.HillClimbingModel`. The hill climbing model
performs gradient descent and stops when it reaches a local
maximum. It takes samples from `log_S` every 10 degrees along the way
and uses the trapezoidal rule to estimate the integral.

```
from mental_rotation.model import HillClimbingModel
hc_model = HillClimbingModel(Xa, Xb)
hc_model.sample()
hc_model.print_stats()
```

### Bayesian Quadrature Model

Located in `lib/mental_rotation/model/bayesian_quadrature.py` or
`mental_rotation.model.BayesianQuadratureModel`. The Bayesian
quadrature model uses the `BQ` object (see below) to estimate a
distribution over $$Z$$. It chooses points that will result in the
lowest expected $$Var(Z)$$, and it samples from `log_S` every 10
degrees along the way. Once the model is confident in its estimate of
$$Z$$, it will stop.

```
from mental_rotation.model import BayesianQuadratureModel
bq_model = BayesianQuadratureModel(Xa, Xb)
bq_model.sample()
bq_model.print_stats()
```

#### Bayesian Quadrature Object

The `BQ` class (located in `lib/mental_rotation/extra/bq.py`, or
`mental_rotation.extra.BQ`) does all the heavy lifting with regards to
computing the Bayesian Quadrature estimate. It implements the
algorithm described in Osborne et al. (2012).

```
from mental_rotation import config

gamma = config.getfloat("bq", "gamma")
ntry = config.getint("bq", "ntry")
n_candidate = config.getint("bq", "n_candidate")
R_mean = config.getfloat("model", "R_mu")
R_var = 1. / config.getfloat("model", "R_kappa")

x = np.random.uniform(-8, 8, 30)
y = scipy.stats.norm.pdf(x, 0, 1)
bq = BQ(x, y, gamma, ntry, n_candidate, R_mean, R_var, s=0)
bq.fit()
print bq.Z_mean(), bq.Z_var()
```

The relevant methods are:

* `BQ.fit()`: finds the MLII estimates for the Gaussian Process
  hyperparameters
* `BQ.S_mean(R)`: computes the estimated mean of `S` at points `R`.
* `BQ.S_cov(R)`: computes the estimated covariance of `S` at points
  `R`.
* `BQ.Z_mean()`: computes the estimated mean of `Z`.
* `BQ.Z_var()`: computes the estimated variance of `Z`.
* `BQ.expected_Z_var(x_a)`: computes the expected variance of `Z`
  given a new observation `x_a`.

Underneath the hood, these methods do a lot of analytical computation,
which is implemented using Cython in the extension module
`mental_rotation.extra.bq_c` (or
`lib/mental_rotation/extra/bq_c.pyx`). For the most part, these
functions compute various analytical solutions to integrals of
Gaussians.

Additionally, the `BQ` object relies heavily on the
[Gaussian process](https://github.com/jhamrick/gaussian_processes)
library written by Jessica Hamrick. This library also implements most
of its functionality in Cython.


## Running simulations

To run simulations, you need to run two processes: the task manager,
which handles which simulations need to be run, and the client, which
receives tasks from the task manager, runs those simulations, and then
sends the data back to the task manager.

The task manager takes a dictionary of simulation parameters called
`params`. It should have the following structure:

* `model` -- `str`, e.g. "GoldStandardModel"
* `version` -- `str`, e.g. "A"
* `num_samples` -- `int`, number of samples per parameter combination
* `chunksize` -- `int`, largest number of simulations per task
* `sim_root` -- `str`, path where the simulations should be saved
* `tasks_path` -- `str`, path to the tasks.json file
* `completed_path` -- `str`, path to the completed.json file
* `stim_paths` -- `list` of `str`, the paths to stimuli
* `model_opts` -- `dict` of model options
   * `S_sigma` -- `list` of `float`, sigma parameter
   * `step` -- `list` of `float`, rotation step size
   * `prior` -- `list` of `float`, prior probability of $h_0$
* `loglevel` -- `str`, e.g. "INFO"

The task manager will then build up a dictionary of tasks. Each task
should be a dictionary with the following structure:

* `model` -- `str`, same as in `params`
* `istim` -- `int`, index into `stim_paths`
* `stim_path` -- `str`, path to stimulus
* `data_path` -- `str`, path to simulation (should be sim root + task name)
* `task_name` -- `str`, name of the task
* `seed` -- `int`, based on the hash of the task name
* `model_opts` -- `dict`, where keys are individual simulation ids and
values are dicts of model options for that specific simulation. The
inner dicts should have keys for `S_sigma`, `step`, `prior`, and
`sample`, and the values should only be a single number (not a list).

## Tests

To run tests, go to the root of the project directory and run:

```
make test
```

This also produces a code coverage report, which can be viewed by
opening `htmlcov/index.html`.

## References

* Osborne, M. A., Duvenaud, D., Garnett, R., Rasmussen, C. E.,
  Roberts, S. J., & Ghahramani, Z. (2012). Active Learning of Model
  Evidence Using Bayesian Quadrature. *Advances in Neural Information
  Processing Systems*, 25.
