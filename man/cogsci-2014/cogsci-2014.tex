% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified: Niels Taatgen (taatgen@cmu.edu) 10/24/2006

%% Change ``a4paper'' in the following line to ``letterpaper'' if you are
%% producing a letter-format document.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{subfig}

\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\Xa}[0]{\mathbf{X}_a}
\newcommand{\Xb}[0]{\mathbf{X}_b}
\newcommand{\Xt}[0]{\mathbf{X}_t}
\newcommand{\R}[0]{\mathbf{R}_\theta}
\newcommand{\F}[0]{\mathbf{F}}
\newcommand{\M}[0]{\mathbf{M}}
\newcommand{\I}[0]{\mathbb{I}}
\newcommand{\hi}[0]{h=0}
\newcommand{\hf}[0]{h=1}
\newcommand{\dif}[0]{\,\mathrm{d}}

\newcommand{\Oc}[0]{Oracle}
\newcommand{\Th}[0]{Threshold}
\newcommand{\Hc}[0]{HC}
\newcommand{\Bq}[0]{BQ}

\newenvironment{pitemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\input{../../results/D/response_time.tex}
\input{../../results/D/response_time_corrs.tex}
\input{../../results/D/accuracy.tex}
\input{../../results/D/accuracy_corrs.tex}
\input{../../results/D/trial_time_corrs.tex}
\input{../../results/D/trial_accuracy_corrs.tex}
\input{../../results/D/num_chance.tex}
\input{../../results/D/theta_time_corrs.tex}
\input{../../results/D/theta_accuracy_corrs.tex}

\title{An active sampling model of mental rotation}
 
\author{{\large \bf Jessica B. Hamrick (jhamrick@berkeley.edu)} \\
  {\large \bf Thomas L. Griffiths (tom\_griffiths@berkeley.edu)} \\
  Department of Psychology, University of California, Berkeley, CA
  94720 USA}

\begin{document}

\maketitle


\begin{abstract}
\TODO{}

\textbf{Keywords:} 
\TODO{}
\end{abstract}

\TODO{put correlations in figures} 

\TODO{need a figure with an example similarity curve, and example
  stimuli}

\section{Introduction}

One of our most astonishing cognitive feats is the ability to
envision, manipulate, and plan with objects -- all without actually
perceiving them. This capacity for ``mental simulation'' has been
widely studied and has sparked intense debate about the underlying
representation of mental images \cite{Kosslyn:2009tj,
  Pylyshyn:2002vk}. Despite this vast literature, there have been
surprisingly few computational models of mental imagery.



\section{Background}

classic result by shepard and metzler

previous models of mental imagery: \cite{Kosslyn:1977tv, Anderson1978,
  Funt:1983wn, Glasgow:1992tj}

assume people rotate until congruent

but how do people actually construct the plan for the rotation?

evidence that people *don't* actually rotate until congruent,
e.g. rotating away from near-perfect matches \cite{Gardony:2013gn}

so what are they actually doing?

perhaps they are performing mental manipulations of an image, but not
a single trajectory of rotation

rational analysis \cite{Marr:1983to,anderson90,Shepard:1987tt}

1) the problem: determine something about the spatial transformations
that an object has undergone
2) the goal: make this determiniation while using the least amount of
resources
3) the solution: perform those rotations and reflections which will
give the most information (?) about the answer until an answer is
found

motivate the active searching approach
\cite{Gureckis:2012gu,Markant:2012uu} \cite{Markant:2012uu,Nelson2007}

we focus less on the representation, and more on the process, assuming
a spatial representation (because you need both to make a claim,
\cite{Anderson1978})

problem solving \cite{Hegarty2004, Schwartz1999}

symbolic vs simulation \cite{Schwartz:1996uy}

eye tracking \cite{Just1976}

\section{Models of mental rotation}

In the mental rotation task, people are presented with pairs of
two-dimensional shapes similar to those used by \citeA{Cooper:1975wp};
an example stimulus is shown in Fig.~\ref{fig:stimuli}. The goal is to
determine whether the two images depict the same shape, or
mirror-image (flipped) shapes.

\subsection{Computational-level analysis}

Formally, we denote the shapes as $X_a$ and $X_b$ and assume $X_b$ is
generated by a transformation of $X_a$, i.e. $X_b=f(X_a, \theta, h)$,
where $\theta$ is a rotation, $h=0$ is the hypothesis that the images
depict the same object, and $h=1$ is the hypothesis that the images
depict mirror-image objects. The posterior probability of each
hypothesis given the observed shapes is then:
\begin{equation}
  p(h\ \vert\ X_a, X_b) \propto \int p(X_b\ \vert\ X_a, \theta, h)p(X_a)p(h)p(\theta)\dif\theta.
  \label{eq:posterior}
\end{equation}
Because we ultimately want to determine which hypothesis is more
likely, the quantity of interest is a ratio:
\begin{equation*}
  \ell := \frac{\int p(X_b\ \vert\ X_a, \theta, \hi)p(X_a)p(\hi)p(\theta)\dif\theta}{\int p(X_b\ \vert\ X_a, \theta, \hf)p(X_a)p(\hf)p(\theta)\dif\theta},
\end{equation*}
which (assuming the two hypotheses are equally likely \textit{a
  priori}, and that all rotations are equally likely) simplifies to:
\begin{equation}
  \ell = \frac{\int p(X_b\ \vert\ X_a, \theta, \hi)\dif\theta}{\int p(X_b\ \vert\ X_a, \theta, \hf)\dif\theta}.
  \label{eq:lh-ratio}
\end{equation}
If $\ell > 1$, then we accept the hypothesis that the images depict
the same object ($\hi$); if $\ell < 1$, then we accept the hypothesis
that the images depict flipped objects ($\hf$).

\subsection{Algorithmic assumptions}

If we represent a shape of $N$ vertices with a $N\times 2$ coordinate
matrix $\mathbf{X}=[\mathbf{x}_1, \ldots{}, \mathbf{x}_N]$, then the
transformation $f$ is $f(\mathbf{X}, h,
\theta):=\mathbf{X}\F_h^T\R^T$, where $\R$ is a rotation matrix,
$\F_0$ is the identity matrix $\I$, and $\F_1$ is a reflection matrix
across the $y$-axis. Assuming no computational constraints, the
simplest solution is to compute the left inverse of $\Xa\F_h^T$ and,
for each $h$, check whether $(\Xa
\F_h^T)_\mathrm{left}^{-1}\cdot{}\Xb$ is a valid rotation matrix.

However, we assume that the ability to compute left inverses is not
available. Instead, the observed shapes may only be transformed by a
small amount at a time, and each transformation is costly in terms of
computational resources. The goal, then is to estimate the integrals
in Eq.~\ref{eq:lh-ratio} by evaluating $p(\Xb\ \vert\ \Xa, \theta, h)$
as few times as possible. 

We define $p(\Xb\ \vert\ \Xa, \theta, h)$ to be the similarity between
$\Xb$ and a transformation of $\Xa$:
\begin{equation}
  p(\Xb\ \vert\ \Xa, \theta, h):= S(\Xb, f(\Xa, h, \theta)).
  \label{eq:likelihood}
\end{equation}
We do not know which vertices of $\Xb$ correspond to which vertices of
$\Xa$, so $S$ must marginalize over the set of possible mappings,
$\mathbb{M}$. For brevity, let $\mathbf{X}_m=\M\cdot{}f(\Xa, h,
\theta)$ where $\M\in\mathbb{M}$ is a permutation matrix. Then:
\begin{equation}
  S(\Xb, f(\Xa, h, \theta)):=\frac{1}{|\mathbb{M}|} \sum_{\M} \prod_{n=1}^N \mathcal{N}(\mathbf{x}_{bn}\ \vert \ \mathbf{x}_{mn}, \I\sigma^2).
  \label{eq:similarity}
\end{equation}

Additionally, we have the constraint of small
transformations. Specifically, if the current mental image is $\Xt$,
then:
\begin{equation}
  \mathbf{X}_{t+1} = \left\{ \begin{array}{ll}
      f(\Xt, 0, \epsilon) &\mbox{ rotate right by $\epsilon$,} \\
      f(\Xt, 0, -\epsilon) &\mbox{ rotate left by $\epsilon$,} \\
      f(\Xt, 1, 0) &\mbox{ flip,} \\
      f(\Xa, 0, 0) &\mbox{ reset, or} \\
      f(\Xa, 1, 0) &\mbox{ reset and flip.} \\
    \end{array} \right.
  \label{eq:actions}
\end{equation}

\subsubsection{\Oc{} model}

The previous hypothesis in the literature is that people perform a
mental rotation in the shortest direction until a match is found, and
that determining this direction is an implementation detail \TODO{cite
  anderson?}. To reflect this hypothesis, we created an ``oracle''
model which knows the correct rotation \textit{a priori}, and simply
performs rotations in the shortest direction until it reaches the
correct rotation.

\subsubsection{\Th{} model}

An intuitive and simple model which does not assume the direction is
known might first rotate in the direction that increases similarity,
and then stop rotating once a ``match'' is found, as determined by a
threshold on the value of $S$. If all rotations have been exhausted,
then flip, and try rotating again.

The consequence of doing a search for a match is that
Eq.~\ref{eq:lh-ratio} becomes a likelihood ratio test, where $\theta$
is set to the MLE value, rather than being marginalized:
\begin{equation}
  \ell = \frac{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hi)}{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hf)}.
  \label{eq:mle-lh-ratio}
\end{equation}

\subsubsection{Hill climbing model}

Unfortunately, it is not always clear what constitutes a good enough
``match''. Many shapes may have multimodal similarity functions
\TODO{refer to figure}, and the maximum possible value of $S$ is
unlikely to be known \textit{a priori} \TODO{cite something about how
  shape matching is hard}. In this case, we must weaken our stopping
criteria: rather than searching for a value above a threshold, we
search for \textit{any} local maximum, as in the Hill Climbing search
algorithm (\Hc{}). Similar to the \Th{} model, we use the (local) MLE
estimate of $\theta$, as in Eq.~\ref{eq:mle-lh-ratio}.

\subsubsection{Bayesian quadrature model}

An alternative to the previous models is not to perform a search for
the MLE, but to approximate the integrals in Eq.~\ref{eq:lh-ratio} by
picking locations to sample which will most improve accuracy of the
estimate. Rather than a point estimate of the ratio, or even a simple
Monte Carlo estimate, we can infer a distribution by placing priors
over the similarity functions themselves:
\begin{equation}
\ell = \frac{\int \left[\int S(\Xb, f(\Xa, \theta, \hi))p(\theta)\dif\theta\right] p(S)\dif S}{\int \left[\int S(\Xb, f(\Xa, \theta, \hf))p(\theta)\dif\theta\right] p(S)\dif S}
\end{equation}
This is a technique known in the machine-learning literature as
\textit{Bayesian Quadrature} (BQ)
\cite{Diaconis:1988uo,OHagan:1991tx,Osborne:2012tm}. Specifically, we
use Gaussian Process (GP) priors, as in \citeA{Osborne:2012tm}
\TODO{probably need to describe better what a GP is}. Because our
domain is on a circle, we utilize a periodic kernel for the covariance
\cite{Rasmussen:2006vz}, i.e. $k(\theta,
\theta^\prime)=h^2\exp[-\frac{2}{w^2}\sin^2(\frac{1}{2}(\theta-\theta^\prime))]$.

Denoting $S_h=S(\Xb, f(\Xa, \theta, h))$, we first place a GP prior on
$\log(S_h)$. Because GPs have no guarantee of non-negativity, placing
the prior over the log enforces positivity after it is exponentiated:
\begin{equation}
\mathbb{E}[Z_h] \approx \int \exp(\mu_h(\theta))p(\theta)\dif\theta,
\end{equation}
where $\mu_h:=\mu(\log S_h)$ is the mean of the log-GP. However, this
integral is still intractable. To approximate it, we fit a second GP
over points sampled from the log-GP.\footnote{Note that the approach
  used here differs slightly from the one presented in
  \citeA{Osborne:2012tm} and is based on personal communication with
  one of the authors \cite{Duvenaud:2013td}.}We will denote these
points as $\bar{S}_h:=\exp(\mu_h)$. Then, from
\citeA{Duvenaud:2013td}:
\begin{align}
  \mathbb{E}[Z_h] &\approx \int \bar{\mu}_h(\theta)p(\theta)\dif\theta,\\
  \mathbb{V}(Z_h) &\approx \iint \mathrm{Cov}_h(\theta,
  \theta^\prime)\bar{\mu}_h(\theta)\bar{\mu}_h(\theta^\prime)p(\theta)p(\theta^\prime)\dif\theta\dif\theta^\prime,
\end{align}
where $\bar{\mu}_h:=\mu(\bar{S}_h)$ is the mean of the second GP, and
$\mathrm{Cov}_h:=\mathrm{Cov}(\log S_h)$ is the covariance of the
log-GP.

Now that we have a distribution over $Z_h$, we can additionally
compute which points which we would expect to strengthen our estimate
(i.e., decrease the variance). From \citeA{Osborne:2012tm}, the
expected variance of $Z_h$ if we sampled a new observation at
$\theta_a$ is:
\begin{align}
\mathbb{E}&[\mathbb{V}(Z_h|\theta_a)]=\mathbb{V}(Z_h) + \mathbb{E}[Z_h] - \\
&\int \mathbb{E}[Z_h|\theta_{a}]^2 \mathcal{N}(\mu_h(\theta_a), \mathrm{Cov}_h(\theta_a, \theta_a))\dif\log S_h(\theta_a).\nonumber
\label{ref:expected-variance}
\end{align}

Revisiting our likelihood ratio, we now have:
\begin{equation}
p(\ell)\approx\frac{\mathcal{N}(\mathbb{E}[Z_0], \mathbb{V}(Z_0))}{\mathcal{N}(\mathbb{E}[Z_1], \mathbb{V}(Z_1))}.
\end{equation}
This distribution does not have a nice form. However, we really are
just interested in whether $Z_0>Z_1$ or $Z_1>Z_0$: thus, rather than
computing $p(\ell)$, we use $Z_D=Z_0-Z_1$. Assuming $Z_0$ and $Z_1$
are independent,\footnote{This assumption is probably not
  correct. \TODO{explanation?}} we have:
\begin{equation}
  p(Z_D)\propto\mathcal{N}(\mathbb{E}[Z_0] - \mathbb{E}[Z_1], \mathbb{V}(Z_0) + \mathbb{V}(Z_1)).
\end{equation}
We then sample new observations until we are at least 95\% confident
that $Z_D\neq 0$. In other words, when $p(Z_D<0)<0.025$, we accept
$h=0$, and when $p(Z_D<0)>0.975$, we accept $h=1$.

\section{Methods}


\subsection{Stimuli}

We randomly generated 20 shapes of 5 or 6 vertices (e.g., $\Xa$ in
Figure \ref{fig:stimuli}). For each shape, we computed 20 ``same'' and
20 ``flipped'' stimuli pairs, with $\theta$ spaced at $20^\prime$
increments between 0 and 360 (with 0 and 180 degree rotations repeated
twice, in order to gather an equal number of responses for each angle
between 0 and 180). ``Same'' pairs were created by rotating $\Xa$ by
$\theta$; ``flipped'' pairs first reflected $\Xa$ across the $y$-axis,
then rotated by $\theta$.

We generated 5 shapes to be used in the practice block. Across all the
practice 10 stimuli, each shape and each angle (60, 120, 180, 240, or
300) was repeated twice (once ``flipped'' and once ``same'') such that
no shape was presented at the same angle twice. Additionally, we
generated a sixth shape to be included along with the instructions,
which had both a ``flipped'' and ``same'' version, each rotated to 320
degrees.

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/response_time.pdf}
    \caption{\textbf{Response times.} \TODO{}}
    \label{fig:response-times}
  \end{center}
\end{figure*}


\subsection{Design}

We recruited 247 participants on Amazon's Mechanical Turk. Each
participant was paid \$1.00 for approximately 15 minutes of work,
consisting of one block of 10 practice trials followed by two blocks
of 100 experiment trials. Within a block, trials were presented in a
random order.

All participants saw the same 10 practice trials (as described
above). There were a total of 800 experimental stimuli (20 shapes
$\times$ 20 angles $\times$ 2 same/flipped), which were split into 8
blocks of 100 across conditions in the following manenr. First,
stimuli were split into four blocks of 200 trials. Within each block,
each shape was repeated 10 times and each rotation was repeated 10
times (5 same, 5 flipped), such that across all blocks, each stimulus
appeared exactly once. Each block was then split in half. Each
participant then completed two half-blocks (not necessarily both from
the original full block).

\subsection{Procedure}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=0.85\textwidth]{../../figures/D/accuracy.pdf}
    \caption{\textbf{Accuracy.} \TODO{}}
    \label{fig:accuracy}
  \end{center}
\end{figure*}

Participants were given the following instructions while being shown
an example ``same'' pair and an example ``flipped'' pair: \textit{``On
  each trial, you will see two images. Sometimes, they show the
  \textbf{same} object. Other times, the images show \textbf{flipped}
  objects. The task is to determine whether the two images show the
  \textbf{same} object or \textbf{flipped} objects.''}

On each trial, particpants were instructed to press the `b' key to
begin and to focus on the fixation cross that appeared for 750
milliseconds afterwards. The two images were then presented
side-by-side, each at 300px $\times$ 300px, and participants could
press `s' to indicate they thought the images depicted the same
object, or `d' to indicate they thought the images depicted flipped
objects.

While there was no limit on response time, participants were urged to
repond as quickly as possible while still being
accurate. Specifically, we asked them to aim for at least 85\%
accuracy in the experimental blocks, and provided a counter to keep
them informed of their score.

\section{Analysis}

Out of the 247 participants, 200 (81\%) were included in our
analyses. Of the rest, we excluded 10 (4\%) because of an experimental
error, 6 (2.4\%) because they had already compelted a previous version
of the experiment, and 31 (12.6\%) because they failed a comprehension
check. A participant was marked as passing the comprehension check if
they answered at least 85\% of ``easy'' trials correctly. ``Easy''
trials were defined to be those for which the presented shapes
differed by a rotation of no more than 20 degrees.

We ran model simulations for the same stimuli that participants
viewed. We ran 10 samples of each stimulus under the \Oc{} model, and
100 samples of each stimulus for the \Th{}, \Hc{}, and
\Bq{} models, with the exception of stimuli where
$\theta=0$ or $\theta=180$, in which case we ran double the number of
samples.

For analyses of response time, confidence intervals were computed
using a bootstrap analysis (sampling with replacement) with 1000
bootstrap samples. Response times were only only considered for
correct responses.

For analyses of accuracy, confidence intervals were
computed from a binomial proportion with a Jeffrey's beta prior.  For
correlations, we performed a bootstrap analysis (sampling with
replacement) over Spearman correlations using 10000 bootstrap samples.

To test if participants or a model was above chance on a particular
stimulus, we used the same posterior and checked whether $p>0.05$ for
the 50\% mark.

\section{Results}

\begin{figure}[t]
  \centering
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_accuracy.pdf}}%
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_time.pdf}}
  \caption{\textbf{Effect of learning.} \TODO{}}
  \label{fig:learning}
\end{figure}

\subsubsection{Response times}

The average response time across all stimuli was \ExpTime{} seconds,
and the average response time for an individual stimulus ranged from
\ExpTimeMin{} to \ExpTimeMax{} seconds. The average accuracy across
all stimuli was \ExpAccuracy{}, though there were \ExpNumChance{}
individual stimuli (out of 720) for which people were not above
chance.

As expected, the minimum angle of rotation was significanty
monotonically correlated with average per-stimulus response times,
both for flipped pairs (\ExpThetaTimeCorrFlipped{}) and same pairs
(\ExpThetaTimeCorrSame{}). This was also the case for the number of
actions taken by the \Oc{} model (\OcThetaTimeCorr{}), the \Th{}
model (\ThThetaTimeCorr{}), and the \Bq{} model
(\BqThetaTimeCorr{}), but not the \Hc{} model
(\HcThetaTimeCorr{}). Fig.~\ref{fig:response-times}a

The number of actions taken by the \Oc{} model was the best predictor
of human response times, with a correlation of \ExpOcTimeCorr{}. The
\Th{} model was the next best (\ExpThTimeCorr{}), with the \Bq{} model
not far behind (\ExpBqTimeCorr{}). The \Hc{} model was not
significantly correlated with people (\ExpHcTimeCorr{}).

\TODO{flipped response times higher than same response times for
  smaller angles?}

\subsubsection{Accuracy}

Of the models, the \Oc{} and \Th{} models peformed perfectly,
with 100\% accuracy. The \Bq{} model was very accurate
overall (\BqAccuracy{}), though there were \BqNumChance{} stimuli for
which it was not above chance. The \Hc{} model was not
particularly accurate, and although it did perform above chance
overall (\HcAccuracy{}), there were \HcNumChance{} individual stimuli
for which it was not above chance.

The minimum angle was also correlated with the average per-stimulus
accuracy: for flipped pairs, \ExpThetaAccuracyCorrFlipped{}, and for
same pairs, \ExpThetaAccuracyCorrSame{}. There was also a significant
effect for the \Hc{} model (\HcThetaAccuracyCorr{}) and the
\Bq{} model
(\BqThetaAccuracyCorr{}). Fig.~\ref{fig:accuracy}

There was a moderate correlation between the accuracy of the \Hc{}
model and human accuracy (\ExpHcAccuracyCorr{}). The \Bq{} model had a
similar correlation, with \ExpBqAccuracyCorr{}.

\subsubsection{Practice effects} 

There was a significant effect of learning both on response time
(\ExpTrialTimeCorr{}) and on accuracy (\ExpTrialAccuracyCorr{}),
though the effect on accuracy was not significant during the second
half of the experiment (\ExpaTrialAccuracyCorr{} for the first half
vs. \ExpbTrialAccuracyCorr{} for the second
half). Fig.~\ref{fig:learning}


\section{Discussion}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/model-traces.pdf}
    \caption{\textbf{Model traces.} \TODO{} \TODO{put pictures of the
        stimuli here}}
    \label{fig:model-traces}
  \end{center}
\end{figure*}

We replicated the previous monotonic response time result, though not
the linear resulte. Actually kind of similar to \cite{Gardony:2013gn}
\TODO{elaborate}

Also replicated the constant accuracy for flipped stimuli, but not for
same stimuli, from \cite{Cooper:1975wp}. Why is this? Maybe the
strategy is ``they are different until proven the same''.

None of the models were particularly good fits to human data. The best
fit was the \Oc{} model, though this is not satisfying because the
\Oc{} model knows the answer beforehand, which people obviously do
not. The next best model, the \Th{} model, is also not a
particularly satisfying account, because it knows the global maximum
\textit{a priori}, which is not a reasonable assumption. \TODO{explain
  why it is faster for 180 than mid angles -- it is because for a lot
  of stimuli, there is rotational symmetry at 180, so it almost always
  starts checking the correct version first. For mid angles, it might
  check the wrong version first, meaning it takes much longer.}

The \Bq{} model makes more reasonable assumptions about the observer's
knowledge, but has its own problems. Because it is forced to take
small steps, it often gets stuck sampling the same region over and
over again, particularly for stimuli with larger rotations
(Fig.~\ref{fig:model-traces}). As a result, its response time curve is
convex rather than concave.

Other problems: evidence that rotations aren't actually holistic
\cite{Yuille:1982tx}, eye movements \cite{Just1976}

\TODO{talk about how these results suggest a model of mental rotation
  is harder than was previous thought, and that this is a first step
  towards detangling these issues.}

\section{Acknowledgments}

This research was supported by ONR MURI grant number N00014-13-1-0341,
and a Berkeley Fellowship awarded to JBH.

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{references}

\end{document}
