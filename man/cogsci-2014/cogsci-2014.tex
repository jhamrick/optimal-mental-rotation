% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified: Niels Taatgen (taatgen@cmu.edu) 10/24/2006

%% Change ``a4paper'' in the following line to ``letterpaper'' if you are
%% producing a letter-format document.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{subfig}

\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\Xa}[0]{\mathbf{X}_a}
\newcommand{\Xb}[0]{\mathbf{X}_b}
\newcommand{\Xt}[0]{\mathbf{X}_t}
\newcommand{\R}[0]{\mathbf{R}_\theta}
\newcommand{\F}[0]{\mathbf{F}}
\newcommand{\M}[0]{\mathbf{M}}
\newcommand{\I}[0]{\mathbb{I}}
\newcommand{\hi}[0]{h=0}
\newcommand{\hf}[0]{h=1}
\newcommand{\dif}[0]{\,\mathrm{d}}

\newcommand{\Oc}[0]{Oracle}
\newcommand{\Th}[0]{Threshold}
\newcommand{\Hc}[0]{HC}
\newcommand{\Bq}[0]{BQ}

\newenvironment{pitemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\input{../../results/D/response_time.tex}
\input{../../results/D/response_time_corrs.tex}
\input{../../results/D/accuracy.tex}
\input{../../results/D/accuracy_corrs.tex}
\input{../../results/D/trial_time_corrs.tex}
\input{../../results/D/trial_accuracy_corrs.tex}
\input{../../results/D/num_chance.tex}
\input{../../results/D/theta_time_corrs.tex}
\input{../../results/D/theta_accuracy_corrs.tex}

\title{Modeling mental rotation}
 
\author{{\large \bf Jessica B. Hamrick (jhamrick@berkeley.edu)} \\
  {\large \bf Thomas L. Griffiths (tom\_griffiths@berkeley.edu)} \\
  Department of Psychology, University of California, Berkeley, CA
  94720 USA}

\begin{document}

\maketitle


\begin{abstract}
\TODO{}

\textbf{Keywords:} 
\TODO{}
\end{abstract}

\TODO{put correlations in figures} 

\TODO{need a figure with an example similarity curve, and example
  stimuli}

\TODO{fix title}

\section{Introduction}

One of our most astonishing cognitive feats is the ability to
envision, manipulate, and plan with objects -- all without actually
perceiving them. This capacity for ``mental simulation'' has been
widely studied and has sparked intense debate about the underlying
representation of mental images \cite<e.g.,>{Kosslyn:2009tj,
  Pylyshyn:2002vk}. Despite this vast literature, there have been
surprisingly few computational models of mental imagery.

In the classic experiment by \citeA{Shepard1971}, participants viewed
images of three-dimensional objects and had to determine whether the
images depicted the same object (which differed by a rotation) or two
separate objects (which differed by a reflection and a rotation). The
result was that people's response times had a strong linear
correlation with the minimum angle of rotation. The conclusion was
that people were solving this task by ``mentally rotating'' the
objects until they were congruent.

However, there are some questions regarding this process of problem
solving that are not explained by the alignment hypothesis: how do
people know the axis around which to rotate the objects? If the axis
is known, how do people know which direction to rotate the objects?
And finally, how do people know when to stop rotating and give a
response? 

In this paper, we attempt to address these questions through a
rational analysis \cite{Marr:1983to,anderson90,Shepard:1987tt} of four
models of mental rotation. First, we discuss the previous literature
on mental imagery. Second, we outline computational- and
algorithmic-level analyses of the problem of mental rotation. Then, we
describe a behavioral experiment based on the classic mental rotation
studies \cite<e.g.,>{Cooper:1975wp}, and compare the results of the
experiment with each of the models. We conclude with a discussion of
the strengths and weaknesses of each model, and lay out directions for
future work.

\section{Background}

Previous models of mental rotation have, for the most part, focused
mostly on the representation of mental images, rather than how people
decide \textit{which} mental images to
simulate. \citeA{Kosslyn:1977tv} propose a model of mental imagery's
visual buffer, but not the planning process of how it is used;
similarly, \citeA{Glasgow:1992tj} are mostly concerned with the
knowledge representation of imagery. Although \citeA{Anderson1978}
emphasizes the importance of considering both representation and
process, he dismisses the problem of determining the direction and
axis of rotation as merely a ``technical difficulty''.

The only model (of which the authors are aware) that has more
seriously attempted to address concerns regarding which simulation to
run is the parallel-process model of mental rotation by
\citeA{Funt:1983wn}. He determines the direction and axis of rotation
using the method-of-moments method; once this target rotation
computed, his model rotates one object until the target rotation is
reached, and then compares the two to see if they are
congruent. \TODO{?}

However, there is evidence that people do not actually rotate until
the objects are congruent, but rather pay attention to certain salient
features of the object, rather than a holistic representation
\cite{Just1976,Yuille:1982tx}. More recent evidence shows that when
people perform physical rotations, they do not rotate until congruency
is reached and may even rotate \textit{away} from near perfect matches
\cite{Gardony:2013gn}. Moreover, the state-of-the-art in computer
vision suggests that there is more to shape matching than simply
checking for congruency, particularly when shapes are complex or when
the shapes might not be exactly the same
\cite<e.g.,>{Belongie:2002tj,Sebastian:2003vm}.

so what are they actually doing?

perhaps they are performing mental manipulations of an image, but not
a single trajectory of rotation

\subsection{A rational analysis of mental rotation}

rational analysis \cite{Marr:1983to,anderson90,Shepard:1987tt}

1) the problem: determine something about the spatial transformations
that an object has undergone
2) the goal: make this determiniation while using the least amount of
resources
3) the solution: perform those rotations and reflections which will
give the most information (?) about the answer until an answer is
found

motivate the active searching approach
\cite{Gureckis:2012gu,Markant:2012uu} \cite{Markant:2012uu,Nelson2007}

we focus less on the representation, and more on the process, assuming
a spatial representation (because you need both to make a claim,
\cite{Anderson1978})

problem solving \cite{Hegarty2004, Schwartz1999}

symbolic vs simulation \cite{Schwartz:1996uy}

eye tracking \cite{Just1976}

\section{Models of mental rotation}

In the mental rotation task, people are presented with pairs of
two-dimensional shapes similar to those used by \citeA{Cooper:1975wp};
an example stimulus is shown in Fig.~\ref{fig:stimuli}. The goal is to
determine whether the two images depict the same shape, or
mirror-image (flipped) shapes.

here we use simple 2d models as a starting point, but the general case
of solving this problem is very difficult, \TODO{cite shape matching
  literature}

\subsection{Computational-level analysis}

Formally, we denote the shapes as $X_a$ and $X_b$ and assume $X_b$ is
generated by a transformation of $X_a$, i.e. $X_b=f(X_a, \theta, h)$,
where $\theta$ is a rotation, $h=0$ is the hypothesis that the images
depict the same object, and $h=1$ is the hypothesis that the images
depict mirror-image objects. The posterior probability of each
hypothesis given the observed shapes is then:
\begin{equation}
  p(h\ \vert\ X_a, X_b) \propto \int p(X_b\ \vert\ X_a, \theta, h)p(X_a)p(h)p(\theta)\dif\theta,
  \label{eq:posterior}
\end{equation}
where $p(X_b\ \vert\ X_a, \theta, h)$ is the probability that $X_b$
was generated from $X_a$, and $p(X_a)$ is the probability of observing
$X_a$. Because we ultimately want to determine which hypothesis is
more likely, the quantity of interest is a ratio $\ell:=p(h=0\ \vert\
X_a, X_b) / p(h=1\ \vert\ X_a, X_b)$ which (assuming that all
rotations are equally likely) simplifies to:
\begin{equation}
  \ell = \frac{\left(\int p(X_b\ \vert\ X_a, \theta, \hi)\dif\theta\right)p(h=0)}{\left(\int p(X_b\ \vert\ X_a, \theta, \hf)\dif\theta\right)p(h=1)}.
  \label{eq:lh-ratio}
\end{equation}
If $\ell > 1$, then we accept the hypothesis that the images depict
the same object ($\hi$); if $\ell < 1$, then we accept the hypothesis
that the images depict flipped objects ($\hf$).

\subsection{Algorithmic assumptions}

We represent a shape of $N$ vertices with a $N\times 2$ coordinate
matrix $\mathbf{X}=[\mathbf{x}_1, \ldots{}, \mathbf{x}_N]$, and denote
the rotation and/or reflection transformation as $f(\mathbf{X}, h,
\theta):=\mathbf{X}\F_h^T\R^T$, where $\R$ is a rotation matrix, and
$\F_h$ is either the identity matrix $\I$ (when $h=0$) or a reflection
matrix across the $y$-axis (when $h=1$).  We assume that the observed
shapes may only be transformed by a small amount at a time, and each
transformation is costly in terms of computational resources. The
goal, then is to estimate the integrals in Eq.~\ref{eq:lh-ratio} by
evaluating $p(\Xb\ \vert\ \Xa, \theta, h)$ as few times as possible.

We define $p(\Xb\ \vert\ \Xa, \theta, h)$ to be the similarity between
$\Xb$ and a transformation of $\Xa$:
\begin{equation}
  p(\Xb\ \vert\ \Xa, \theta, h):= S(\Xb, f(\Xa, h, \theta)).
  \label{eq:likelihood}
\end{equation}
We do not know which vertices of $\Xb$ correspond to which vertices of
$\Xa$, so $S$ must marginalize over the set of possible mappings,
$\mathbb{M}$. For brevity, let $\mathbf{X}_m=\M\cdot{}f(\Xa, h,
\theta)$ where $\M\in\mathbb{M}$ is a permutation matrix. Then:
\begin{equation}
  S(\Xb, f(\Xa, h, \theta)):=\frac{1}{|\mathbb{M}|} \sum_{\M} \prod_{n=1}^N \mathcal{N}(\mathbf{x}_{bn}\ \vert \ \mathbf{x}_{mn}, \I\sigma^2).
  \label{eq:similarity}
\end{equation}

Additionally, we have the constraint of small
transformations. Specifically, if the current mental image is $\Xt$,
then:
\begin{equation}
  \mathbf{X}_{t+1} = \left\{ \begin{array}{ll}
      f(\Xt, 0, \epsilon) &\mbox{ rotate right by $\epsilon$,} \\
      f(\Xt, 0, -\epsilon) &\mbox{ rotate left by $\epsilon$,} \\
      f(\Xt, 1, 0) &\mbox{ flip,} \\
      f(\Xa, 0, 0) &\mbox{ reset, or} \\
      f(\Xa, 1, 0) &\mbox{ reset and flip.} \\
    \end{array} \right.
  \label{eq:actions}
\end{equation}

To summarize, we approximate the likelihood term of
Eq.~\ref{eq:lh-ratio} using the similarity function defined in
Eq.~\ref{eq:similarity}. Because we assume analog rotations, this
similarity can only be computed at sequential locations, i.e. the
actions listed in Eq.~\ref{eq:actions}.

\subsection{Specific models}

The last decision we need to make is which algorithm to use to
approximate Eq.~\ref{eq:lh-ratio} using samples of the similarity
function. The algorithm must do two things: first, it must choose
\textit{which} places to sample, and second, it must decide when to
stop sampling.

\subsubsection{\Oc{} model}

One hypothesis in the literature is that people perform a mental
rotation in the shortest direction until a match is found
\cite{Shepard1971, Cooper:1975wp}, and that determining this direction
is an implementation detail \cite{Anderson1978}, or that it is
computed beforehand \cite{Funt:1983wn}.  To reflect this hypothesis,
we created an ``oracle'' model which first computes the correct
rotation and then simply takes actions in the shortest direction until
it reaches the point where the shapes are aligned.

To determine the correct rotation, we solve for the rotation matrix by
computing $(\Xa \F_h^T)_\mathrm{left}^{-1}\cdot{}\Xb$, where
$(\Xa\F_h^T)_\mathrm{left}^{-1}$ is the left inverse of
$\Xa\F_h^T$. For each $h$, we then check whether the resulting matrix
is a valid rotation matrix.

\subsubsection{\Th{} model}

An intuitive and simple model which does not know which way to rotate
\textit{a priori} might first rotate in the direction that increases
similarity, and then stop rotating once a ``match'' is found, as
determined by a threshold on the value of $S$. If all rotations have
been exhausted, then flip, and try rotating again.

We note, however, that it is not always clear what constitutes a good
enough ``match''. In the current formulation of the problem, we know
the exact geometry of the shapes, and know that a linear
transformation exists which will perfectly align the shapes. However,
shapes could be more complex and/or three-dimensional, be subject to
perceptual uncertainty, or even be not exactly identical. In these
cases, it is not clear how to choose a reasonable threshold \textit{a
  priori}, as the global optimum will depend on many factors. Thus, it
is unlikely that the \Th{} model will not be robust beyond this
domain.

The consequence of doing a search for a match is that
Eq.~\ref{eq:lh-ratio} becomes a likelihood ratio test, where $\theta$
is set to the MLE value, rather than being marginalized:
\begin{equation}
  \ell = \frac{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hi)}{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hf)}.
  \label{eq:mle-lh-ratio}
\end{equation}

\subsubsection{Hill climbing model}

One way to deal with the problem of choosing a threshold would simply
be to perform an exhaustive search or use a global optimisation
strategy. However, these strategies would not result in the linear
response time found by \citeA{Shepard1971}. A second alternative,
which could potentially demonstrate the linear response time result,
might instead just perform a Hill Climbing (\Hc{}) search for a
\textit{local} maximum. However, it is not necessarily the case that
all local maxima for the correct hypothesis will be higher than all
the local maxima for the incorrect hypothesis: thus, we would expect
the \Hc{} model to have difficulties reliably choosing the correct
hypothesis.

\subsubsection{Bayesian quadrature model}

While the previous few models have all focused on \textit{searching}
for the global maximum, the goal is really to just approximate
Eq.~\ref{eq:lh-ratio} while still obeying the constraint of sequential
rotations. Instead of perfoming a search, we could try maintaining a
probability distribution over our \textit{estimate}, and then choose
actions which are expected to improve the estimate of
Eq.~\ref{eq:lh-ratio}. This strategy has several obvious
benefits. First, it does not make assumptions about the shape or scale
of the similarity function. Second, by choosing to sample places which
are informative, this method implicitly minimizes the amount of
rotation, but because it is constrained to sequential rotations,
should still exhibit the linear effect of the angle.

Rather than a point estimate of the ratio, or even a simple
Monte Carlo estimate, we can infer a distribution by placing priors
over the similarity functions themselves:
\begin{equation}
\ell = \frac{\int \left[\int S(\Xb, f(\Xa, \theta, \hi))p(\theta)\dif\theta\right] p(S)\dif S}{\int \left[\int S(\Xb, f(\Xa, \theta, \hf))p(\theta)\dif\theta\right] p(S)\dif S}
\end{equation}
This is a technique known in the machine-learning literature as
\textit{Bayesian Quadrature} (BQ)
\cite{Diaconis:1988uo,OHagan:1991tx,Osborne:2012tm}. Specifically, we
use Gaussian Process (GP) priors, as in \citeA{Osborne:2012tm}
\TODO{probably need to describe better what a GP is}. Because our
domain is on a circle, we utilize a periodic kernel for the covariance
\cite{Rasmussen:2006vz}, i.e. $k(\theta,
\theta^\prime)=h^2\exp[-\frac{2}{w^2}\sin^2(\frac{1}{2}(\theta-\theta^\prime))]$.

Denoting $S_h=S(\Xb, f(\Xa, \theta, h))$, we first place a GP prior on
$\log(S_h)$. Because GPs have no guarantee of non-negativity, placing
the prior over the log enforces positivity after it is exponentiated:
\begin{equation}
\mathbb{E}[Z_h] \approx \int \exp(\mu_h(\theta))p(\theta)\dif\theta,
\end{equation}
where $\mu_h:=\mu(\log S_h)$ is the mean of the log-GP. However, this
integral is still intractable. To approximate it, we fit a second GP
over points sampled from the log-GP.\footnote{Note that the approach
  used here differs slightly from the one presented in
  \citeA{Osborne:2012tm} and is based on personal communication with
  one of the authors \cite{Duvenaud:2013td}.}We will denote these
points as $\bar{S}_h:=\exp(\mu_h)$. Then, from
\citeA{Duvenaud:2013td}:
\begin{align}
  \mathbb{E}[Z_h] &\approx \int \bar{\mu}_h(\theta)p(\theta)\dif\theta,\\
  \mathbb{V}(Z_h) &\approx \iint \mathrm{Cov}_h(\theta,
  \theta^\prime)\bar{\mu}_h(\theta)\bar{\mu}_h(\theta^\prime)p(\theta)p(\theta^\prime)\dif\theta\dif\theta^\prime,
\end{align}
where $\bar{\mu}_h:=\mu(\bar{S}_h)$ is the mean of the second GP, and
$\mathrm{Cov}_h:=\mathrm{Cov}(\log S_h)$ is the covariance of the
log-GP.

Now that we have a distribution over $Z_h$, we can additionally
compute which points which we would expect to strengthen our estimate
(i.e., decrease the variance). From \citeA{Osborne:2012tm}, the
expected variance of $Z_h$ if we sampled a new observation at
$\theta_a$ is:
\begin{align}
\mathbb{E}&[\mathbb{V}(Z_h|\theta_a)]=\mathbb{V}(Z_h) + \mathbb{E}[Z_h] - \\
&\int \mathbb{E}[Z_h|\theta_{a}]^2 \mathcal{N}(\mu_h(\theta_a), \mathrm{Cov}_h(\theta_a, \theta_a))\dif\log S_h(\theta_a).\nonumber
\label{ref:expected-variance}
\end{align}

Revisiting our likelihood ratio, we now have:
\begin{equation}
p(\ell)=p\left(\frac{Z_0}{Z_1}\right)\approx\frac{\mathcal{N}(Z_0\ \vert\ \mathbb{E}[Z_0], \mathbb{V}(Z_0))}{\mathcal{N}(Z_1\ \vert\ \mathbb{E}[Z_1], \mathbb{V}(Z_1))}.
\end{equation}
This distribution does not have a nice form. However, we really are
just interested in whether $Z_0>Z_1$ or $Z_1>Z_0$: thus, rather than
computing $p(\ell)$, we use $Z_D=Z_0-Z_1$. Assuming $Z_0$ and $Z_1$
are independent,\footnote{This assumption is probably not
  correct. \TODO{explanation?}} we have:
\begin{equation}
  p(Z_D)\propto\mathcal{N}(\mathbb{E}[Z_0] - \mathbb{E}[Z_1], \mathbb{V}(Z_0) + \mathbb{V}(Z_1)).
\end{equation}
We then sample new observations until we are at least 95\% confident
that $Z_D\neq 0$. In other words, when $p(Z_D<0)<0.025$, we accept
$h=0$, and when $p(Z_D<0)>0.975$, we accept $h=1$.

\section{Methods}


\subsection{Stimuli}

We randomly generated 20 shapes of 5 or 6 vertices (e.g., $\Xa$ in
Figure \ref{fig:stimuli}). For each shape, we computed 20 ``same'' and
20 ``flipped'' stimuli pairs, with $\theta$ spaced at $20^\prime$
increments between 0 and 360 (with 0 and 180 degree rotations repeated
twice, in order to gather an equal number of responses for each angle
between 0 and 180). ``Same'' pairs were created by rotating $\Xa$ by
$\theta$; ``flipped'' pairs first reflected $\Xa$ across the $y$-axis,
then rotated by $\theta$.

We generated 5 shapes to be used in the practice block. Across all the
practice 10 stimuli, each shape and each angle (60, 120, 180, 240, or
300) was repeated twice (once ``flipped'' and once ``same'') such that
no shape was presented at the same angle twice. Additionally, we
generated a sixth shape to be included along with the instructions,
which had both a ``flipped'' and ``same'' version, each rotated to 320
degrees.

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/response_time.pdf}
    \caption{\textbf{Response times.} \TODO{}}
    \label{fig:response-times}
  \end{center}
\end{figure*}


\subsection{Participants and Design}

We recruited 247 participants on Amazon's Mechanical Turk. Each
participant was paid \$1.00 for approximately 15 minutes of work,
consisting of one block of 10 practice trials followed by two blocks
of 100 experiment trials. Within a block, trials were presented in a
random order.

All participants saw the same 10 practice trials (as described
above). There were a total of 800 experimental stimuli (20 shapes
$\times$ 20 angles $\times$ 2 same/flipped), which were split into 8
blocks of 100 across conditions in the following manenr. First,
stimuli were split into four blocks of 200 trials. Within each block,
each shape was repeated 10 times and each rotation was repeated 10
times (5 same, 5 flipped), such that across all blocks, each stimulus
appeared exactly once. Each block was then split in half. Each
participant then completed two half-blocks (not necessarily both from
the original full block).

\subsection{Procedure}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=0.85\textwidth]{../../figures/D/accuracy.pdf}
    \caption{\textbf{Accuracy.} \TODO{}}
    \label{fig:accuracy}
  \end{center}
\end{figure*}

Participants were given the following instructions while being shown
an example ``same'' pair and an example ``flipped'' pair: \textit{``On
  each trial, you will see two images. Sometimes, they show the
  \textbf{same} object. Other times, the images show \textbf{flipped}
  objects. The task is to determine whether the two images show the
  \textbf{same} object or \textbf{flipped} objects.''}

On each trial, particpants were instructed to press the `b' key to
begin and to focus on the fixation cross that appeared for 750
milliseconds afterwards. The two images were then presented
side-by-side, each at 300px $\times$ 300px, and participants could
press `s' to indicate they thought the images depicted the same
object, or `d' to indicate they thought the images depicted flipped
objects.

While there was no limit on response time, participants were urged to
repond as quickly as possible while still being
accurate. Specifically, we asked them to aim for at least 85\%
accuracy in the experimental blocks, and provided a counter to keep
them informed of their score.

\section{Results}

\subsection{General analysis}

Out of the 247 participants, 200 (81\%) were included in our
analyses. Of the rest, we excluded 10 (4\%) because of an experimental
error, 6 (2.4\%) because they had already compelted a previous version
of the experiment, and 31 (12.6\%) because they failed a comprehension
check. A participant was marked as passing the comprehension check if
they answered at least 85\% of ``easy'' trials correctly. ``Easy''
trials were defined to be those for which the presented shapes
differed by a rotation of no more than 20 degrees.

We ran model simulations for the same stimuli that participants
viewed. We ran 10 samples of each stimulus under each of the modesl,
with the exception of stimuli where $\theta=0$ or $\theta=180$, in
which case we ran double the number of samples.

For analyses of response time, confidence intervals were computed
using a bootstrap analysis (sampling with replacement) with 1000
bootstrap samples. Response times were only only considered for
correct responses.

For analyses of accuracy, confidence intervals were
computed from a binomial proportion with a Jeffrey's beta prior.  For
correlations, we performed a bootstrap analysis (sampling with
replacement) over Spearman correlations using 10000 bootstrap samples.

To test if participants or a model was above chance on a particular
stimulus, we used the same posterior and checked whether $p>0.05$ for
the 50\% mark.

\begin{figure}[t]
  \centering
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_accuracy.pdf}}%
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_time.pdf}}
  \caption{\textbf{Effect of learning.} \TODO{}}
  \label{fig:learning}
\end{figure}

\subsection{Response times}

The average response time across all stimuli was \ExpTime{} seconds,
and the average response time for an individual stimulus ranged from
\ExpTimeMin{} to \ExpTimeMax{} seconds.  As expected, the minimum
angle of rotation was significanty monotonically correlated with
average per-stimulus response times, both for flipped pairs
(\ExpThetaTimeCorrFlipped{}) and same pairs
(\ExpThetaTimeCorrSame{}). This was also the case for the number of
actions taken by the \Oc{} model (\OcThetaTimeCorr{}), the \Th{} model
(\ThThetaTimeCorr{}), and the \Bq{} model (\BqThetaTimeCorr{}), but
not the \Hc{} model
(\HcThetaTimeCorr{}). Fig.~\ref{fig:response-times}a

The number of actions taken by the \Oc{} model was the best predictor
of human response times, with a correlation of \ExpOcTimeCorr{}. The
\Th{} model was the next best (\ExpThTimeCorr{}), with the \Bq{} model
not far behind (\ExpBqTimeCorr{}). The \Hc{} model was not
significantly correlated with people (\ExpHcTimeCorr{}).

\TODO{flipped response times higher than same response times for
  smaller angles?}

\subsection{Accuracy}

The average accuracy across all stimuli was \ExpAccuracy{}, though
there were \ExpNumChance{} individual stimuli (out of 720) for which
people were not above chance. Of the models, the \Oc{} and \Th{}
models peformed perfectly, with 100\% accuracy. The \Bq{} model was
very accurate overall (\BqAccuracy{}), though there were
\BqNumChance{} stimuli for which it was not above chance. The \Hc{}
model was not particularly accurate, and although it did perform above
chance overall (\HcAccuracy{}), there were \HcNumChance{} individual
stimuli for which it was not above chance.

The minimum angle was also correlated with the average per-stimulus
accuracy: for flipped pairs, \ExpThetaAccuracyCorrFlipped{}, and for
same pairs, \ExpThetaAccuracyCorrSame{}. There was also a significant
effect for the \Hc{} model (\HcThetaAccuracyCorr{}) and the
\Bq{} model
(\BqThetaAccuracyCorr{}). Fig.~\ref{fig:accuracy}

There was a moderate correlation between the accuracy of the \Hc{}
model and human accuracy (\ExpHcAccuracyCorr{}). The \Bq{} model had a
similar correlation, with \ExpBqAccuracyCorr{}.

\subsection{Practice effects} 

There was a significant effect of learning both on response time
(\ExpTrialTimeCorr{}) and on accuracy (\ExpTrialAccuracyCorr{}),
though the effect on accuracy was not significant during the second
half of the experiment (\ExpaTrialAccuracyCorr{} for the first half
vs. \ExpbTrialAccuracyCorr{} for the second
half). Fig.~\ref{fig:learning}


\section{Discussion}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/model-traces.pdf}
    \caption{\textbf{Model traces.} \TODO{} \TODO{put pictures of the
        stimuli here}}
    \label{fig:model-traces}
  \end{center}
\end{figure*}

We replicated the previous monotonic response time result, though not
the linear resulte. Actually kind of similar to \cite{Gardony:2013gn}
\TODO{elaborate}

Also replicated the constant accuracy for flipped stimuli, but not for
same stimuli, from \cite{Cooper:1975wp}. Why is this? Maybe the
strategy is ``they are different until proven the same''.

None of the models were particularly good fits to human data. The best
fit was the \Oc{} model, though this is not satisfying because the
\Oc{} model knows the answer beforehand, which people obviously do
not. The next best model, the \Th{} model, is also not a
particularly satisfying account, because it knows the global maximum
\textit{a priori}, which is not a reasonable assumption. \TODO{explain
  why it is faster for 180 than mid angles -- it is because for a lot
  of stimuli, there is rotational symmetry at 180, so it almost always
  starts checking the correct version first. For mid angles, it might
  check the wrong version first, meaning it takes much longer.}

The \Bq{} model makes more reasonable assumptions about the observer's
knowledge, but has its own problems. Because it is forced to take
small steps, it often gets stuck sampling the same region over and
over again, particularly for stimuli with larger rotations
(Fig.~\ref{fig:model-traces}). As a result, its response time curve is
convex rather than concave.

Other problems: evidence that rotations aren't actually holistic
\cite{Yuille:1982tx}, eye movements \cite{Just1976}

\TODO{talk about how these results suggest a model of mental rotation
  is harder than was previous thought, and that this is a first step
  towards detangling these issues.}

\section{Acknowledgments}

This research was supported by ONR MURI grant number N00014-13-1-0341,
and a Berkeley Fellowship awarded to JBH.

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{references}

\end{document}
