% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified: Niels Taatgen (taatgen@cmu.edu) 10/24/2006

%% Change ``a4paper'' in the following line to ``letterpaper'' if you are
%% producing a letter-format document.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{subfig}

\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\Xa}[0]{\mathbf{X}_a}
\newcommand{\Xb}[0]{\mathbf{X}_b}
\newcommand{\Xt}[0]{\mathbf{X}_t}
\newcommand{\R}[0]{\mathbf{R}_\theta}
\newcommand{\F}[0]{\mathbf{F}}
\newcommand{\M}[0]{\mathbf{M}}
\newcommand{\I}[0]{\mathbb{I}}
\newcommand{\hi}[0]{h=0}
\newcommand{\hf}[0]{h=1}
\newcommand{\dif}[0]{\,\mathrm{d}}

\newcommand{\Oc}[0]{Oracle}
\newcommand{\Th}[0]{Threshold}
\newcommand{\Hc}[0]{HC}
\newcommand{\Bq}[0]{BQ}

\newenvironment{pitemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\input{../../results/D/response_time.tex}
\input{../../results/D/response_time_corrs.tex}
\input{../../results/D/accuracy.tex}
\input{../../results/D/accuracy_corrs.tex}
\input{../../results/D/trial_time_corrs.tex}
\input{../../results/D/trial_accuracy_corrs.tex}
\input{../../results/D/num_chance.tex}
\input{../../results/D/theta_time_corrs.tex}
\input{../../results/D/theta_accuracy_corrs.tex}

\title{Modeling mental simulation: a computational analysis of mental rotation}
 
\author{{\large \bf Jessica B. Hamrick (jhamrick@berkeley.edu)} \\
  {\large \bf Thomas L. Griffiths (tom\_griffiths@berkeley.edu)} \\
  Department of Psychology, University of California, Berkeley, CA
  94720 USA}

\begin{document}

\maketitle


\begin{abstract}
\TODO{}

\textbf{Keywords:} 
\TODO{}
\end{abstract}

\TODO{put correlations in figures} 

\TODO{need a figure with an example similarity curve, and example
  stimuli}

\TODO{fix title}

\section{Introduction}

One of our most astonishing cognitive feats is the ability to
envision, manipulate, and plan with objects -- all without actually
perceiving them. This capacity for ``mental simulation'' has been
widely studied and has sparked intense debate about the underlying
representation of mental images \cite<e.g.,>{Kosslyn:2009tj,
  Pylyshyn:2002vk}. Despite this vast literature, there have been
surprisingly few computational models of mental imagery.

In the classic experiment by \citeA{Shepard1971}, participants viewed
images of three-dimensional objects and had to determine whether the
images depicted the same object (which differed by a rotation) or two
separate objects (which differed by a reflection and a rotation). The
result was that people's response times had a strong linear
correlation with the minimum angle of rotation. The conclusion was
that people were solving this task by ``mentally rotating'' the
objects until they were congruent.

However, there are some questions regarding this process of problem
solving that are not explained by the alignment hypothesis: how do
people know the axis around which to rotate the objects? If the axis
is known, how do people know which direction to rotate the objects?
And finally, how do people know when to stop rotating and give a
response? 

In this paper, we explore these questions through rational analysis
\cite{Marr:1983to,anderson90,Shepard:1987tt} and compare four models
of mental rotation. First, we discuss the previous literature on
mental imagery. Second, we outline computational- and
algorithmic-level analyses of the problem of mental rotation. Then, we
describe a behavioral experiment based on the classic mental rotation
studies \cite<e.g.,>{Cooper:1975wp}, and compare the results of the
experiment with each of the models. We conclude with a discussion of
the strengths and weaknesses of each model, and lay out directions for
future work.

\section{Background}

\TODO{say something here}

\subsection{Mechanisms behind mental rotation}

Previous models of mental rotation have, for the most part, focused
mostly on the representation of mental images, rather than how people
decide \textit{which} mental images to
simulate. \citeA{Kosslyn:1977tv} propose a model of mental imagery's
visual buffer, but not the planning process of how it is used;
similarly, \citeA{Glasgow:1992tj} are mostly concerned with the
knowledge representation of imagery. Although \citeA{Anderson1978}
emphasizes the importance of considering both representation and
process, he dismisses the problem of determining the direction and
axis of rotation as merely a ``technical difficulty''.

The only model (of which the authors are aware) that has more
seriously attempted to address concerns regarding which simulation to
run is the parallel-process model of mental rotation by
\citeA{Funt:1983wn}. He determines the direction and axis of rotation
using the method-of-moments method; once this target rotation
computed, his model rotates one object until the target rotation is
reached, and then compares the two to see if they are congruent. This
is a somewhat unsatisfying explanation, however: why would it be
necessary to perform the rotation if the answer is already known?

Perhaps people do not engage in a single trajectory of rotation that
ends with congruency. Some evidence suggests that people do not
perform a holistic rotation until the objects are congruent, but
rather pay attention to certain salient features of the object
\cite{Just1976,Yuille:1982tx}. A more recent study shows that when
performing \textit{physical} rotations, people do not rotate until
congruency is reached, and may even rotate \textit{away} from near
perfect matches \cite{Gardony:2013gn}. Moreover, the state-of-the-art
in computer vision suggests that there is more to shape matching than
simply checking for congruency, particularly when shapes are complex
or when the shapes might not be exactly the same
\cite<e.g.,>{Belongie:2002tj,Sebastian:2003vm}.


\subsection{A rational analysis of mental rotation}

It may be useful to take a step back and try to analyze mental
rotation from using rational analysis
\cite{Marr:1983to,anderson90,Shepard:1987tt}. At the computational
level, we could say that the \textit{problem} is to determine
something about the spatial transformations that an object has
undergone. At the algorithmic level, we are constrained by the notion
that mental images must be transformed in an analog manner (or at
least in a way that is approximately analog), and that mental images
are time-consuming and effortful to generate. Thus, the \textit{goal}
is to make this determiniation while using the least amount of
resources. Due to the sequential constratiant, the minimum amount of
computation will coincide with the minimum angle of rotation. So, the
rational \textit{solution} will be something that only rotates through
the minimum angle.

motivate the active searching approach
\cite{Gureckis:2012gu,Markant:2012uu} \cite{Markant:2012uu,Nelson2007}

problem solving \cite{Hegarty2004, Schwartz1999}

symbolic vs simulation \cite{Schwartz:1996uy}

\section{Modeling mental rotation}

In the mental rotation task, people are presented with pairs of
two-dimensional shapes similar to those used by \citeA{Cooper:1975wp};
an example stimulus is shown in Fig.~\ref{fig:stimuli}. The goal is to
determine whether the two images depict the same shape, or
mirror-image (flipped) shapes.

here we use simple 2d models as a starting point, but the general case
of solving this problem is very difficult, \TODO{cite shape matching
  literature}

\subsection{Computational-level analysis}

Formally, we denote the shapes as $X_a$ and $X_b$ and assume $X_b$ is
generated by a transformation of $X_a$, i.e. $X_b=f(X_a, \theta, h)$,
where $\theta$ is a rotation, $\hi$ is the hypothesis that the images
depict the same object, and $\hf$ is the hypothesis that the images
depict mirror-image objects. The posterior probability of each
hypothesis given the observed shapes is then:
\begin{equation}
  p(h\ \vert\ X_a, X_b) \propto \int p(X_b\ \vert\ X_a, \theta, h)p(X_a)p(h)p(\theta)\dif\theta,
  \label{eq:posterior}
\end{equation}
where $p(X_b\ \vert\ X_a, \theta, h)$ is the probability that $X_b$
was generated from $X_a$, and $p(X_a)$ is the probability of observing
$X_a$. Because we ultimately want to determine which hypothesis is
more likely, the quantity of interest is a ratio $\ell:=p(\hi\ \vert\
X_a, X_b) / p(\hf\ \vert\ X_a, X_b)$ which (assuming that all
rotations are equally likely) simplifies to:
\begin{equation}
  \ell = \frac{\left(\int p(X_b\ \vert\ X_a, \theta, \hi)\dif\theta\right)p(\hi)}{\left(\int p(X_b\ \vert\ X_a, \theta, \hf)\dif\theta\right)p(\hf)}.
  \label{eq:lh-ratio}
\end{equation}
If $\ell > 1$, then we accept the hypothesis that the images depict
the same object ($\hi$); if $\ell < 1$, then we accept the hypothesis
that the images depict flipped objects ($\hf$).

\subsection{Algorithmic assumptions}

We represent a shape of $N$ vertices with a $N\times 2$ coordinate
matrix $\mathbf{X}=[\mathbf{x}_1, \ldots{}, \mathbf{x}_N]$, and denote
the rotation and/or reflection transformation as $f(\mathbf{X}, h,
\theta):=\mathbf{X}\F_h^T\R^T$, where $\R$ is a rotation matrix, and
$\F_h$ is either the identity matrix $\I$ (when $\hi$) or a reflection
matrix across the $y$-axis (when $\hf$).

We define $p(\Xb\ \vert\ \Xa, \theta, h)$ to be the similarity between
$\Xb$ and a transformation of $\Xa$:
\begin{equation}
  p(\Xb\ \vert\ \Xa, \theta, h):= S(\Xb, f(\Xa, h, \theta)).
  \label{eq:likelihood}
\end{equation}
We do not know which vertices of $\Xb$ correspond to which vertices of
$\Xa$, so $S$ must marginalize over the set of possible mappings,
$\mathbb{M}$. For brevity, let $\mathbf{X}_m=\M\cdot{}f(\Xa, h,
\theta)$ where $\M\in\mathbb{M}$ is a permutation matrix. Then:
\begin{equation}
  S(\Xb, f(\Xa, h, \theta)):=\frac{1}{|\mathbb{M}|} \sum_{\M} \prod_{n=1}^N \mathcal{N}(\mathbf{x}_{bn}\ \vert \ \mathbf{x}_{mn}, \I\sigma_S^2),
  \label{eq:similarity}
\end{equation}
where $\sigma_S=0.15$ is the standard deviation of the similarity.

Additionally, we assume that the observed shapes may only be
transformed by a small amount at a time, and each transformation is
costly in terms of computational resources. Specifically, if the
current mental image is $\Xt$, then:
\begin{equation}
  \mathbf{X}_{t+1} = \left\{ \begin{array}{ll}
      f(\Xt, 0, |\epsilon|) &\mbox{ rotate by $\epsilon$,} \\
      f(\Xt, 1, 0) &\mbox{ flip,} \\
      f(\Xa, 0, 0) &\mbox{ reset, or} \\
      f(\Xa, 1, 0) &\mbox{ reset and flip,} \\
    \end{array} \right.
  \label{eq:actions}
\end{equation}
where $\epsilon\sim \mathcal{N}(0, \sigma_\epsilon)$ and
$\sigma_\epsilon=0.6$ is the standard deviation of the step size in
radians.

To summarize, we approximate the likelihood term of
Eq.~\ref{eq:lh-ratio} using the similarity function defined in
Eq.~\ref{eq:similarity}. Because we assume mental rotations are
performed sequentially, this similarity can only be computed for the
actions listed in Eq.~\ref{eq:actions}.

\subsection{Specific models of mental rotation}

In order to approximate Eq.~\ref{eq:lh-ratio} using samples of the
similarity function, we must decide \textit{which} places to sample
and \textit{when} stop sampling. The models below differ in how they
make these decisions.

\subsubsection{Oracle model}

One hypothesis in the literature is that people perform a mental
rotation in the shortest direction until a match is found
\cite{Shepard1971, Cooper:1975wp}, and that determining this direction
is an implementation detail \cite{Anderson1978}, or that it is
computed beforehand \cite{Funt:1983wn}.  To reflect this hypothesis,
we created an ``oracle'' model which first computes the correct
rotation and then simply takes actions in the shortest direction until
it reaches the point where the shapes are aligned.

To determine the correct rotation, we solve for the rotation matrix by
computing $(\Xa \F_h^T)_\mathrm{left}^{-1}\cdot{}\Xb$, where
$(\Xa\F_h^T)_\mathrm{left}^{-1}$ is the left inverse of
$\Xa\F_h^T$. We then check each $h$ to see if computation produces a
valid rotation matrix; the $h$ that does produce a rotation matrix is
the correct hypothesis. This approach gives us the true value of
$\theta$, so Eq.~\ref{eq:lh-ratio} becomes a likelihood ratio test,
where $\theta$ is set to the MLE value, rather than being
marginalized:
\begin{equation}
  \ell = \frac{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hi)p(\hi)}{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hf)p(\hf)}.
  \label{eq:mle-lh-ratio}
\end{equation}

\subsubsection{Threshold model}

An intuitive and simple model which does not know which way to rotate
\textit{a priori} might first rotate in the direction that increases
similarity, and then stop rotating once a ``match'' is found, as
determined by a threshold on the value of $S$. If all rotations have
been exhausted, then flip, and try rotating again. We assume the value
of $S$ which is greater than the threshold corresponds to the true
$\theta$, or a point near the true $\theta$. So, as with the \Oc{}
model, Eq.~\ref{eq:lh-ratio} becomes a likelihood ratio.

We note that in the current formulation of the problem, choosing the
threshold is straightforward because we know both the exact geometry
of the shapes and that a linear transformation exists which will
perfectly align them. However, it is not always clear how to choose a
reasonable threshold \textit{a priori}, as the global optimum will
depend on many factors (such as shape complexity, dimensionality,
perceptual uncertainty, and whether the shapes are exactly
identical). Thus, it is unlikely that the \Th{} model will be robust
beyond this domain.

\subsubsection{Hill climbing model}

One way to deal with the problem of choosing a threshold would simply
be to perform an exhaustive search or use a global optimisation
strategy. However, these strategies would not result in the linear
response time found by \citeA{Shepard1971}. A second alternative,
which could potentially demonstrate the linear response time result,
might instead just perform a Hill Climbing (\Hc{}) search for a
\textit{local} maximum. As with the \Oc{} and \Th{} models,
Eq.~\ref{eq:lh-ratio} becomes a maximum likelihood ratio. Unlike the
global maximum, however, it is not guaranteed that a local maximum of
the correct hypothesis will be greater than a local maximum of the
incorrect hypothesis.

\subsubsection{Bayesian quadrature model}

While the previous few models have all focused on \textit{searching}
for the global maximum, the goal is really to just approximate
Eq.~\ref{eq:lh-ratio} while still obeying the constraint of sequential
rotations. Instead of perfoming a search, we could try maintaining a
probability distribution over our \textit{estimate} of
Eq.~\ref{eq:lh-ratio}, and then choose actions which are expected to
improve the accuracy of the estimate. This strategy has several
obvious benefits. First, it does not make assumptions about the shape
or scale of the similarity function. Second, by choosing to sample
places which are informative, this method implicitly minimizes the
amount of rotation, but because it is constrained to sequential
rotations, should still exhibit the linear effect of the angle.

Formally, we denote $Z_h$ as our estimate of the likelihood for
hypothesis $h$, and write its distribution as:
\begin{equation}
  p(Z_h) = \int \left[\int S(\Xb, f(\Xa, \theta, h))p(\theta)\dif\theta\right] p(S)\dif S.
\end{equation}
This is a technique known in the machine-learning literature as
\textit{Bayesian Quadrature} (BQ)
\cite{Diaconis:1988uo,OHagan:1991tx,Osborne:2012tm}. Specifically, we
use a Gaussian Process (GP) prior for $p(S)$, as in
\citeA{Osborne:2012tm}.\footnote{Because our domain is on a circle, we
  utilize a periodic kernel for the covariance
  \cite{Rasmussen:2006vz}, i.e. $k(\theta,
  \theta^\prime)=h^2\exp[-\frac{2}{w^2}\sin^2(\frac{1}{2}(\theta-\theta^\prime))]$.}
Denoting $S_h=S(\Xb, f(\Xa, \theta, h))$, we first place a GP prior on
the log of $S_h$ in order to enforce positivity after it is
exponentiated:
\begin{equation}
\mathbb{E}[Z_h] \approx \int \exp(\mu_h(\theta))p(\theta)\dif\theta,
\end{equation}
where $\mu_h:=\mu(\log S_h)$ is the mean of the log-GP. However, this
integral is still intractable. To approximate it, we fit a second GP
over points sampled from the log-GP, which we denote as
$\bar{S}_h:=\exp(\mu_h)$.\footnote{Note that the approach used here
  differs slightly from the one presented in \citeA{Osborne:2012tm}
  and is based on personal communication with one of the authors
  \cite{Duvenaud:2013td}.} Then, from \citeA{Duvenaud:2013td}:
\begin{align}
  \mathbb{E}[Z_h] &\approx \int \bar{\mu}_h(\theta)p(\theta)\dif\theta,\\
  \mathbb{V}(Z_h) &\approx \iint \mathrm{Cov}_h(\theta,
  \theta^\prime)\bar{\mu}_h(\theta)\bar{\mu}_h(\theta^\prime)p(\theta)p(\theta^\prime)\dif\theta\dif\theta^\prime,
\end{align}
where $\bar{\mu}_h:=\mu(\bar{S}_h)$ is the mean of the second GP, and
$\mathrm{Cov}_h:=\mathrm{Cov}(\log S_h)$ is the covariance of the
log-GP.

Assuming independence, we can now write $p(Z_h)\approx\mathcal{N}(Z_h\
\vert\ \mathbb{E}[Z_h], \mathbb{V}(Z_h))$, which gives us a
distribution over the likelihood ratio in Eq.~\ref{eq:lh-ratio}:
\begin{equation}
p(\ell)\approx\frac{\mathcal{N}(Z_0\ \vert\ \mathbb{E}[Z_0], \mathbb{V}(Z_0))\ p(\hi)}{\mathcal{N}(Z_1\ \vert\ \mathbb{E}[Z_1], \mathbb{V}(Z_1))\ p(\hf)}.
\end{equation}
This distribution cannot easily be calculated; however, we really are
just interested in whether $Z_0>Z_1$ or $Z_1>Z_0$. Thus, rather than
computing $p(\ell)$, we use $Z_D=Z_0-Z_1$:
\begin{equation}
  p(Z_D)\propto\mathcal{N}(\mathbb{E}[Z_0] - \mathbb{E}[Z_1], \mathbb{V}(Z_0) + \mathbb{V}(Z_1)).
\end{equation}
We then sample new observations until we are at least 95\% confident
that $Z_D\neq 0$. In other words, when $p(Z_D<0)<0.025$, we accept
$\hi$, and when $p(Z_D<0)>0.975$, we accept $\hf$. To determine which
points to sample, we can compute the expected variance of $Z_h$ if we
sampled a new observation at $\theta_a$. From \citeA{Osborne:2012tm}:
\begin{align}
\mathbb{E}&[\mathbb{V}(Z_h|\theta_a)]=\mathbb{V}(Z_h) + \mathbb{E}[Z_h] - \\
&\int \mathbb{E}[Z_h|\theta_{a}]^2 \mathcal{N}(\mu_h(\theta_a), \mathrm{Cov}_h(\theta_a, \theta_a))\dif\log S_h(\theta_a).\nonumber
\label{ref:expected-variance}
\end{align}
We compute this expected variance for each of the actions in
Eq.~\ref{eq:actions}, and then choose the action with the lowest
value.

\section{Methods}


\subsection{Stimuli}

We randomly generated 20 shapes of 5 or 6 vertices (e.g., $\Xa$ in
Figure \ref{fig:stimuli}). For each shape, we computed 20 ``same'' and
20 ``flipped'' stimuli pairs, with $\theta$ spaced at $20^\prime$
increments between 0 and 360 (with 0 and 180 degree rotations repeated
twice, in order to gather an equal number of responses for each angle
between 0 and 180). ``Same'' pairs were created by rotating $\Xa$ by
$\theta$; ``flipped'' pairs first reflected $\Xa$ across the $y$-axis,
then rotated by $\theta$.

We generated 5 shapes to be used in the practice block. Across all the
practice 10 stimuli, each shape and each angle (60, 120, 180, 240, or
300) was repeated twice (once ``flipped'' and once ``same'') such that
no shape was presented at the same angle twice. Additionally, we
generated a sixth shape to be included along with the instructions,
which had both a ``flipped'' and ``same'' version, each rotated to 320
degrees.

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/response_time.pdf}
    \caption{\textbf{Response times.} \TODO{}}
    \label{fig:response-times}
  \end{center}
\end{figure*}


\subsection{Participants and Design}

We recruited 247 participants on Amazon's Mechanical Turk. Each
participant was paid \$1.00 for approximately 15 minutes of work,
consisting of one block of 10 practice trials followed by two blocks
of 100 experiment trials. Within a block, trials were presented in a
random order.

All participants saw the same 10 practice trials (as described
above). There were a total of 800 experimental stimuli (20 shapes
$\times$ 20 angles $\times$ 2 same/flipped), which were split into 8
blocks of 100 across conditions in the following manenr. First,
stimuli were split into four blocks of 200 trials. Within each block,
each shape was repeated 10 times and each rotation was repeated 10
times (5 same, 5 flipped), such that across all blocks, each stimulus
appeared exactly once. Each block was then split in half. Each
participant then completed two half-blocks (not necessarily both from
the original full block).

\subsection{Procedure}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=0.85\textwidth]{../../figures/D/accuracy.pdf}
    \caption{\textbf{Accuracy.} \TODO{}}
    \label{fig:accuracy}
  \end{center}
\end{figure*}

Participants were given the following instructions while being shown
an example ``same'' pair and an example ``flipped'' pair: \textit{``On
  each trial, you will see two images. Sometimes, they show the
  \textbf{same} object. Other times, the images show \textbf{flipped}
  objects. The task is to determine whether the two images show the
  \textbf{same} object or \textbf{flipped} objects.''}

On each trial, particpants were instructed to press the `b' key to
begin and to focus on the fixation cross that appeared for 750
milliseconds afterwards. The two images were then presented
side-by-side, each at 300px $\times$ 300px, and participants could
press `s' to indicate they thought the images depicted the same
object, or `d' to indicate they thought the images depicted flipped
objects.

While there was no limit on response time, participants were urged to
repond as quickly as possible while still being
accurate. Specifically, we asked them to aim for at least 85\%
accuracy in the experimental blocks, and provided a counter to keep
them informed of their score.

\section{Results}

Out of the 247 participants, 200 (81\%) were included in our
analyses. Of the rest, we excluded 10 (4\%) because of an experimental
error, 6 (2.4\%) because they had already compelted a previous version
of the experiment, and 31 (12.6\%) because they failed a comprehension
check. A participant was marked as passing the comprehension check if
they answered at least 85\% of ``easy'' trials correctly. ``Easy''
trials were defined to be those for which the presented shapes
differed by a rotation of no more than 20 degrees.

We ran model simulations for the same stimuli that participants
viewed. We ran 10 samples of each stimulus under each of the modesl,
with the exception of stimuli where $\theta=0$ or $\theta=180$, in
which case we ran double the number of samples.

For analyses of response time, confidence intervals were computed
using a bootstrap analysis (sampling with replacement) with 1000
bootstrap samples. Response times were only only considered for
correct responses.

For analyses of accuracy, confidence intervals were
computed from a binomial proportion with a Jeffrey's beta prior.  For
correlations, we performed a bootstrap analysis (sampling with
replacement) over Spearman correlations using 10000 bootstrap samples.

To test if participants or a model was above chance on a particular
stimulus, we used the same posterior and checked whether $p>0.05$ for
the 50\% mark.

\begin{figure}[t]
  \centering
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_accuracy.pdf}}%
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_time.pdf}}
  \caption{\textbf{Effect of learning.} \TODO{}}
  \label{fig:learning}
\end{figure}

\subsection{Practice effects} 

There was a significant effect of learning both on response time
(\ExpTrialTimeCorr{}) and on accuracy (\ExpTrialAccuracyCorr{}),
though the effect on accuracy was not significant during the second
half of the experiment (\ExpaTrialAccuracyCorr{} for the first half
vs. \ExpbTrialAccuracyCorr{} for the second
half). Fig.~\ref{fig:learning}


\subsection{Response times}

The average response time across all stimuli was \ExpTime{} seconds,
and the average response time for an individual stimulus ranged from
\ExpTimeMin{} to \ExpTimeMax{} seconds.  As expected, the minimum
angle of rotation was significanty monotonically correlated with
average per-stimulus response times, both for flipped pairs
(\ExpThetaTimeCorrFlipped{}) and same pairs
(\ExpThetaTimeCorrSame{}). This was also the case for the number of
actions taken by the \Oc{} model (\OcThetaTimeCorr{}), the \Th{} model
(\ThThetaTimeCorr{}), and the \Bq{} model (\BqThetaTimeCorr{}), but
not the \Hc{} model
(\HcThetaTimeCorr{}). Fig.~\ref{fig:response-times}a

The number of actions taken by the \Oc{} model was the best predictor
of human response times, with a correlation of \ExpOcTimeCorr{}. The
\Th{} model was the next best (\ExpThTimeCorr{}), with the \Bq{} model
not far behind (\ExpBqTimeCorr{}). The \Hc{} model was not
significantly correlated with people (\ExpHcTimeCorr{}).

\TODO{flipped response times higher than same response times for
  smaller angles?}

\subsection{Accuracy}

The average accuracy across all stimuli was \ExpAccuracy{}, though
there were \ExpNumChance{} individual stimuli (out of 720) for which
people were not above chance. Of the models, the \Oc{} and \Th{}
models peformed perfectly, with 100\% accuracy. The \Bq{} model was
very accurate overall (\BqAccuracy{}), though there were
\BqNumChance{} stimuli for which it was not above chance. The \Hc{}
model was not particularly accurate, and although it did perform above
chance overall (\HcAccuracy{}), there were \HcNumChance{} individual
stimuli for which it was not above chance.

The minimum angle was also correlated with the average per-stimulus
accuracy: for flipped pairs, \ExpThetaAccuracyCorrFlipped{}, and for
same pairs, \ExpThetaAccuracyCorrSame{}. There was also a significant
effect for the \Hc{} model (\HcThetaAccuracyCorr{}) and the
\Bq{} model
(\BqThetaAccuracyCorr{}). Fig.~\ref{fig:accuracy}

There was a moderate correlation between the accuracy of the \Hc{}
model and human accuracy (\ExpHcAccuracyCorr{}). The \Bq{} model had a
similar correlation, with \ExpBqAccuracyCorr{}.


\section{Discussion}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/model-traces.pdf}
    \caption{\textbf{Model traces.} \TODO{} \TODO{put pictures of the
        stimuli here}}
    \label{fig:model-traces}
  \end{center}
\end{figure*}

We replicated the previous monotonic response time result, though not
the linear resulte. Actually kind of similar to \cite{Gardony:2013gn}
\TODO{elaborate}

Also replicated the constant accuracy for flipped stimuli, but not for
same stimuli, from \cite{Cooper:1975wp}. Why is this? Maybe the
strategy is ``they are different until proven the same''.

None of the models were particularly good fits to human data. The best
fit was the \Oc{} model, though this is not satisfying because the
\Oc{} model knows the answer beforehand, which people obviously do
not. The next best model, the \Th{} model, is also not a
particularly satisfying account, because it knows the global maximum
\textit{a priori}, which is not a reasonable assumption. \TODO{explain
  why it is faster for 180 than mid angles -- it is because for a lot
  of stimuli, there is rotational symmetry at 180, so it almost always
  starts checking the correct version first. For mid angles, it might
  check the wrong version first, meaning it takes much longer.}

The \Bq{} model makes more reasonable assumptions about the observer's
knowledge, but has its own problems. Because it is forced to take
small steps, it often gets stuck sampling the same region over and
over again, particularly for stimuli with larger rotations
(Fig.~\ref{fig:model-traces}). As a result, its response time curve is
convex rather than concave.

Other problems: evidence that rotations aren't actually holistic
\cite{Yuille:1982tx}, eye movements \cite{Just1976}

\TODO{talk about how these results suggest a model of mental rotation
  is harder than was previous thought, and that this is a first step
  towards detangling these issues.}

\section{Acknowledgments}

This research was supported by ONR MURI grant number N00014-13-1-0341,
and a Berkeley Fellowship awarded to JBH.

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{references}

\end{document}
