% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified: Niels Taatgen (taatgen@cmu.edu) 10/24/2006

%% Change ``a4paper'' in the following line to ``letterpaper'' if you are
%% producing a letter-format document.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage{apacite}
\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{subfig}

\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\Xa}[0]{\mathbf{X}_a}
\newcommand{\Xb}[0]{\mathbf{X}_b}
\newcommand{\Xt}[0]{\mathbf{X}_t}
\newcommand{\R}[0]{\mathbf{R}_\theta}
\newcommand{\F}[0]{\mathbf{F}}
\newcommand{\M}[0]{\mathbf{M}}
\newcommand{\I}[0]{\mathbb{I}}
\newcommand{\hi}[0]{h=0}
\newcommand{\hf}[0]{h=1}
\newcommand{\dif}[0]{\,\mathrm{d}}

\newenvironment{pitemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}

\input{../../results/D/response_time.tex}
\input{../../results/D/response_time_corrs.tex}
\input{../../results/D/accuracy.tex}
\input{../../results/D/accuracy_corrs.tex}
\input{../../results/D/trial_time_corrs.tex}
\input{../../results/D/trial_accuracy_corrs.tex}

\title{An active sampling model of mental rotation}
 
\author{{\large \bf Jessica B. Hamrick (jhamrick@berkeley.edu)} \\
  {\large \bf Thomas L. Griffiths (tom\_griffiths@berkeley.edu)} \\
  Department of Psychology, University of California, Berkeley, CA
  94720 USA}

\begin{document}

\maketitle


\begin{abstract}
\TODO{}

\textbf{Keywords:} 
\TODO{}
\end{abstract}


\section{Introduction}

One of our most astonishing cognitive feats is the ability to
envision, manipulate, and plan with objects -- all without actually
perceiving them. This capacity for ``mental simulation'' has been
widely studied and has sparked intense debate about the underlying
representation of mental images \TODO{cite}. Despite this vast
literature, there have been surprisingly few computational models of
mental imagery.



\section{Background}

classic result by shepard and metzler

assume people rotate until congruent

but how do people actually construct the plan for the rotation?

evidence that people *don't* actually rotate until congruent

so what are they actually doing?

perhaps they are performing mental manipulations of an image, but not
a single trajectory of rotation

rational analysis \cite{Marr:1983to,anderson90,Shepard:1987tt}

1) the problem: determine something about the spatial transformations
that an object has undergone
2) the goal: make this determiniation while using the least amount of
resources
3) the solution: perform those rotations and reflections which will
give the most information (?) about the answer until an answer is
found

motivate the active searching approach
\cite{Gureckis:2012gu,Markant:2012uu} \cite{Markant:2012uu,Nelson2007}

we focus less on the representation, and more on the process, assuming
a spatial representation (because you need both to make a claim,
\cite{Anderson1978})

problem solving \cite{Hegarty2004, Schwartz1999}

symbolic vs simulation \cite{Schwartz:1996uy}

eye tracking \cite{Just1976}

\section{Models of mental rotation}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/model-traces.pdf}
    \caption{\textbf{Model traces.}}
    \label{fig:model-traces}
  \end{center}
\end{figure*}

In the mental rotation task, people are presented with pairs of
two-dimensional shapes similar to those used by \cite{Cooper:1975wp}
(e.g., Figure \ref{fig:stimuli}) and must determine whether the two
images depict the same shape, or mirror-image shapes.

\subsection{Computational-level analysis}

Formally, we denote the shapes as $X_a$ and $X_b$ and assume $X_b$ is
generated by a transformation of $X_a$, i.e. $X_b=f(X_a, \theta, h)$,
where $\theta$ is a rotation, $h=0$ is the hypothesis that the images
depict the same object, and $h=1$ is the hypothesis that the images
depict mirror-image objects. The posterior probability of each
hypothesis given the observed shapes is then:
\begin{equation}
  p(h\ \vert\ X_a, X_b) \propto \int p(X_b\ \vert\ X_a, \theta, h)p(X_a)p(h)p(\theta)\dif\theta.
  \label{eq:posterior}
\end{equation}
Because we ultimately want to determine which hypothesis is more
likely, the quantity of interest is a ratio:
\begin{equation*}
  \ell := \frac{\int p(X_b\ \vert\ X_a, \theta, \hi)p(X_a)p(\hi)p(\theta)\dif\theta}{\int p(X_b\ \vert\ X_a, \theta, \hf)p(X_a)p(\hf)p(\theta)\dif\theta},
\end{equation*}
which (assuming the two hypotheses are equally likely \textit{a
  priori}, and that all rotations are equally likely) simplifies to:
\begin{equation}
  \ell = \frac{\int p(X_b\ \vert\ X_a, \theta, \hi)\dif\theta}{\int p(X_b\ \vert\ X_a, \theta, \hf)\dif\theta}.
  \label{eq:lh-ratio}
\end{equation}
If $\ell > 1$, then we accept the hypothesis that the images depict
the same object ($\hi$); if $\ell < 1$, then we accept the hypothesis
that the images depict flipped objects ($\hf$).

\subsection{Algorithmic assumptions}

If we represent a shape of $N$ vertices with a $N\times 2$ coordinate
matrix $\mathbf{X}=[\mathbf{x}_1, \ldots{}, \mathbf{x}_N]$, then the
transformation $f$ is $f(\mathbf{X}, h,
\theta):=\mathbf{X}\F_h^T\R^T$, where $\R$ is a rotation matrix,
$\F_0$ is the identity matrix $\I$, and $\F_1$ is a reflection matrix
across the $y$-axis. Assuming no computational constraints, the
simplest solution is to compute the left inverse of $\Xa\F_h^T$ and,
for each $h$, check whether $(\Xa
\F_h^T)_\mathrm{left}^{-1}\cdot{}\Xb$ is a valid rotation matrix.

However, we assume that the ability to compute left inverses is not
available. Instead, the observed shapes may only be transformed by a
small amount at a time, and each transformation is costly in terms of
computational resources. The goal, then is to estimate the integrals
in Eq.~\ref{eq:lh-ratio} by evaluating $p(\Xb\ \vert\ \Xa, \theta, h)$
as few times as possible. 

We define $p(\Xb\ \vert\ \Xa, \theta, h)$ to be the similarity between
$\Xb$ and a transformation of $\Xa$:
\begin{equation}
  p(\Xb\ \vert\ \Xa, \theta, h):= S(\Xb, f(\Xa, h, \theta)).
  \label{eq:likelihood}
\end{equation}
We do not know which vertices of $\Xb$ correspond to which vertices of
$\Xa$, so $S$ must marginalize over the set of possible mappings,
$\mathbb{M}$. For brevity, let $\mathbf{X}_m=\M\cdot{}f(\Xa, h,
\theta)$ where $\M\in\mathbb{M}$ is a permutation matrix. Then:
\begin{equation}
  S(\Xb, f(\Xa, h, \theta)):=\frac{1}{|\mathbb{M}|} \sum_{\M} \prod_{n=1}^N \mathcal{N}(\mathbf{x}_{bn}\ \vert \ \mathbf{x}_{mn}, \I\sigma^2).
  \label{eq:similarity}
\end{equation}

Additionally, we have the constraint of small
transformations. Specifically, if the current mental image is $\Xt$,
then:
\begin{equation}
  \mathbf{X}_{t+1} = \left\{ \begin{array}{ll}
      f(\Xt, 0, \epsilon) &\mbox{ rotate right by $\epsilon$,} \\
      f(\Xt, 0, -\epsilon) &\mbox{ rotate left by $\epsilon$,} \\
      f(\Xt, 1, 0) &\mbox{ flip,} \\
      f(\Xa, 0, 0) &\mbox{ reset, or} \\
      f(\Xa, 1, 0) &\mbox{ reset and flip.} \\
    \end{array} \right.
  \label{eq:actions}
\end{equation}

\subsubsection{Threshold-based model}

An intuitive and simple model is to first rotate in the direction that
increases similarity, and then stop rotating once a ``match'' is
found, as determined by a threshold on the value of $S$. If all
rotations have been exhausted, then flip, and try rotating again.

The consequence of doing a search for a match is that
Eq.~\ref{eq:lh-ratio} becomes a likelihood ratio test, where $\theta$
is set to the MLE value, rather than being marginalized:
\begin{equation}
  \ell = \frac{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hi)}{\max_\theta p(\Xb\ \vert\ \Xa, \theta, \hf)}.
  \label{eq:mle-lh-ratio}
\end{equation}

\subsubsection{Hill-climbing model}

Unfortunately, it is not always clear what constitutes a good enough
``match''. Many shapes may have multimodal similarity functions
\TODO{refer to figure}, and the maximum possible value of $S$ is
unlikely to be known \textit{a priori} \TODO{cite something about how
  shape matching is hard}. In this case, we must weaken our stopping
criteria: rather than searching for a value above a threshold, we
search for \textit{any} local maximum.  Similar to the threshold-based
model, we use the (local) MLE estimate of $\theta$, as in
Eq.~\ref{eq:mle-lh-ratio}.

\subsubsection{Confidence-based model}

An alternative to the previous two models is to approximate the
integrals in Eq.~\ref{eq:lh-ratio} by picking locations to sample
which will most improve accuracy of the estimate. Rather than a point
estimate of the ratio, or even a simple Monte Carlo estimate, we can
infer a distribution by placing priors over the similarity functions
themselves:
\begin{equation}
\ell = \frac{\int \left[\int S(\Xb, f(\Xa, \theta, \hi))p(\theta)\dif\theta\right] p(S)\dif S}{\int \left[\int S(\Xb, f(\Xa, \theta, \hf))p(\theta)\dif\theta\right] p(S)\dif S}
\end{equation}
This is a technique known in the machine-learning literature as
\textit{Bayesian Quadrature} (BQ)
\cite{Diaconis:1988uo,OHagan:1991tx,Osborne:2012tm}. Specifically, we
use Gaussian Process (GP) priors \cite{Osborne:2012tm} \TODO{probably
  need to describe better what a GP is}. Because our domain is on a
circle, we utilize a periodic kernel for the covariance
\cite{Rasmussen:2006vz}, i.e. $k(\theta,
\theta^\prime)=h^2\exp[-\frac{2}{w^2}\sin^2(\frac{1}{2}(\theta-\theta^\prime))]$.

Denoting $S_h=S(\Xb, f(\Xa, \theta, h))$, we first place a GP prior on
$\log(S_h)$. Because GPs have no guarantee of non-negativity, placing
the prior over the log enforces positivity after it is exponentiated:
\begin{equation}
\mathbb{E}[Z_h] \approx \int \exp(\mu_h(\theta))p(\theta)\dif\theta,
\end{equation}
where $\mu_h:=\mu(\log S_h)$ is the mean of the log-GP. However, this
integral is still intractable. To approximate it, we fit a second GP
over points sampled from the log-GP.\footnote{Note that the approach
  presented in \cite{Osborne:2012tm} differs slightly from the one
  used here. We chose this newer version after a discussion with one
  of the authors on the original BQ paper \TODO{cite personal
    communication}.}We will denote these points as
$\bar{S}_h:=\exp(\mu_h)$. Then, from \TODO{cite personal
  communication}:
\begin{align}
  \mathbb{E}[Z_h] &\approx \int \bar{\mu}_h(\theta)p(\theta)\dif\theta,\\
  \mathbb{V}(Z_h) &\approx \iint \mathrm{Cov}_h(\theta,
  \theta^\prime)\bar{\mu}_h(\theta)\bar{\mu}_h(\theta^\prime)p(\theta)p(\theta^\prime)\dif\theta\dif\theta^\prime,
\end{align}
where $\bar{\mu}_h:=\mu(\bar{S}_h)$ is the mean of the second GP, and
$\mathrm{Cov}_h:=\mathrm{Cov}(\log S_h)$ is the covariance of the
log-GP.

Now that we have a distribution over $Z_h$, we can additionally
compute which points which we would expect to strengthen our estimate
(i.e., decrease the variance). From \cite{Osborne:2012tm}, the
expected variance of $Z_h$ if we sampled a new observation at
$\theta_a$ is:
\begin{align}
\mathbb{E}&[\mathbb{V}(Z_h|\theta_a)]=\mathbb{V}(Z_h) + \mathbb{E}[Z_h] - \\
&\int \mathbb{E}[Z_h|\theta_{a}]^2 \mathcal{N}(\mu_h(\theta_a), \mathrm{Cov}_h(\theta_a, \theta_a))\dif\log S_h(\theta_a)\nonumber
\label{ref:expected-variance}
\end{align}

Revisiting our likelihood ratio, we now have:
\begin{equation}
p(\ell)\approx\frac{\mathcal{N}(\mathbb{E}[Z_0], \mathbb{V}(Z_0))}{\mathcal{N}(\mathbb{E}[Z_1], \mathbb{V}(Z_1))}
\end{equation}
\TODO{figure out what to do here.}


\section{Methods}


\subsection{Stimuli}

We randomly generated 20 shapes of 5 or 6 vertices (e.g., $\Xa$ in
Figure \ref{fig:stimuli}). For each shape, we computed 20 ``same'' and
20 ``flipped'' stimuli pairs, with $\theta$ spaced at $20^\prime$
increments between 0 and 360 (with 0 and 180 degree rotations repeated
twice, in order to gather an equal number of responses for each angle
between 0 and 180). ``Same'' pairs were created by rotating $\Xa$ by
$\theta$; ``flipped'' pairs first reflected $\Xa$ across the $y$-axis,
then rotated by $\theta$.

We generated 5 shapes to be used in the practice block. Across all the
practice 10 stimuli, each shape and each angle (60, 120, 180, 240, or
300) was repeated twice (once ``flipped'' and once ``same'') such that
no shape was presented at the same angle twice. Additionally, we
generated a sixth shape to be included along with the instructions,
which had both a ``flipped'' and ``same'' version, each rotated to 320
degrees.

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=\textwidth]{../../figures/D/response_time.pdf}
    \caption{\textbf{Response times.}}
    \label{fig:response-times}
  \end{center}
\end{figure*}


\subsection{Design}

We recruited 247 participants on Amazon's Mechanical Turk. Each
participant was paid \$1.00 for approximately 15 minutes of work,
consisting of one block of 10 practice trials followed by two blocks
of 100 experiment trials. Within a block, trials were presented in a
random order.

All participants saw the same 10 practice trials (as described
above). There were a total of 800 experimental stimuli (20 shapes
$\times$ 20 angles $\times$ 2 same/flipped), which were split into 8
blocks of 100 across conditions in the following manenr. First,
stimuli were split into four blocks of 200 trials. Within each block,
each shape was repeated 10 times and each rotation was repeated 10
times (5 same, 5 flipped), such that across all blocks, each stimulus
appeared exactly once. Each block was then split in half. Each
participant then completed two half-blocks (not necessarily both from
the original full block).

\subsection{Procedure}

\begin{figure*}[t]
  \begin{center}
    \includegraphics[width=0.85\textwidth]{../../figures/D/accuracy.pdf}
    \caption{\textbf{Accuracy.}}
    \label{fig:response-times}
  \end{center}
\end{figure*}

Participants were given the following instructions while being shown
an example ``same'' pair and an example ``flipped'' pair: \textit{``On
  each trial, you will see two images. Sometimes, they show the
  \textbf{same} object. Other times, the images show \textbf{flipped}
  objects. The task is to determine whether the two images show the
  \textbf{same} object or \textbf{flipped} objects.''}

On each trial, particpants were instructed to press the `b' key to
begin and to focus on the fixation cross that appeared for 750
milliseconds afterwards. The two images were then presented
side-by-side, each at 300px $\times$ 300px, and participants could
press `s' to indicate they thought the images depicted the same
object, or `d' to indicate they thought the images depicted flipped
objects.

While there was no limit on response time, participants were urged to
repond as quickly as possible while still being
accurate. Specifically, we asked them to aim for at least 85\%
accuracy in the experimental blocks, and provided a counter to keep
them informed of their score.

\section{Analysis}

Out of the 247 participants, 200 (81\%) were included in our
analyses. Of the rest, we excluded 10 (4\%) because of an experimental
error, 6 (2.4\%) because they had already compelted a previous version
of the experiment, and 31 (12.6\%) because they failed a comprehension
check. A participant was marked as passing the comprehension check if
they answered at least 85\% of ``easy'' trials correctly. ``Easy''
trials were defined to be those for which the presented shapes
differed by a rotation of no more than 20 degrees.

We ran model simulations for the same stimuli that participants
viewed. We ran 10 samples of each stimulus under the Oracle model, and
100 samples of each stimulus for the Threshold, Hill Climbing, and
Bayesian Quadrature models, with the exception of stimuli where
$\theta=0$ or $\theta=180$, in which case we ran double the number of
samples.

For all analyses (except those of accuracy), confidence intervals were
computed using a bootstrap analysis with 10000 bootstrap samples. For
analyses of accuracy, confidence intervals were computed from a
binomial proportion with a Jeffrey's beta prior.

\section{Results}

\begin{figure}[t]
  \centering
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_accuracy.pdf}}%
  \subfloat{\includegraphics[width=0.25\textwidth]{../../figures/D/trial_time.pdf}}
  \caption{\textbf{Effect of learning.}}
  \label{fig:learning}
\end{figure}

response time as a function of rotation

accuracy as a function of rotation

practice effects

\section{Discussion}


\section{Acknowledgments}

This research was supported by ONR MURI grant number N00014-13-1-0341,
and a Berkeley Fellowship awarded to JBH.

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{references}

\end{document}
