\documentclass{article} % For LaTeX2e
\usepackage{nips12submit_e,times}
%\documentstyle[nips12submit_09,times,art10]{article} % For LaTeX 2.09

\usepackage{amsmath, amsthm, amssymb}
% \usepackage{natbib}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}

\pagestyle{empty}

\title{Mental Simulation as Bayesian Quadrature}
\author{Jessica B.~Hamrick and Thomas L.~Griffiths\\
  Department of Psychology\\
  University of California, Berkeley\\
  Berkeley, CA 94720\\
  \texttt{\{jhamrick,tom\_griffiths\}@berkeley.edu}}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\TODO}[1]{\textcolor{red}{[TODO: #1]}}
\newcommand{\MSE}[0]{\mathrm{MSE}}
\newcommand{\ME}[0]{\mathrm{ME}}
\newcommand{\naive}[0]{na\"ive}
\newcommand{\Naive}[0]{Na\"ive}

\include{nips-2013-analyses}

%\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
\TODO{}
\end{abstract}

\section{Introduction}

One of the challenges of solving any computational problem is
determining how best to use the available computing resources. For
example, a computer can render complex graphics faster by recognizing
that this kind of computation should be carried out by a specialized
graphics processor. The same challenge arises in designing an
intelligent agent: how should the agent make best use of its computing
resources? Recent research on rational models of human cognition has
provided insight into the nature of the computational problems that
human beings need to solve (e.g. \cite{Chater:1999wp,Griffiths2012a}),
but leaves open the question of how people allocate their resources in
solving those problems. In this paper, we take a step towards
addressing this question, applying rational analysis (in the spirit of
\cite{Marr:1983to,anderson90} \TODO{shepard?}) to one aspect of human
metacognition: the use of mental simulation.

Consider the images on the left in Figure
\ref{fig:mental-rotation}. In each panel, are the two depicted objects
identical (except for a rotation), or distinct? When presented with
this mental rotation task, people default to a strategy in which they
visualize one object rotating until it is congruent with the other
\cite{Shepard1971}. There is strong evidence for such mental
simulation: we can imagine three-dimensional objects in our minds and
manipulate them, to a certain extent, as if they were real
\cite{Kosslyn:2009tj}.  However, the use of mental simulation is
predicated on determining appropriate parameters to give the
simulation, analogous to determining exactly what computation should
be passed to a graphics processor.  In the case of the classic mental
rotation task, we might ask: How do people know which way to rotate
the object?  When should one stop rotating and accept the hypothesis
that the objects are different?

Recent work in cognitive science has shown how problems of allocating
cognitive resources to solving computational problems can be analyzed
using the methods of statistical decision theory
\cite{Lieder:2012wg,Vul:2009wy}. We apply this ``rational
metacognition'' approach to the problem of mental rotation. We
investigate several computational solutions to this task and
qualitatively compare them to human mental rotation performance. In
particular, we argue that performing mental rotation can be framed as
an integration problem, with the direction of rotation becoming a
statistical design problem (or in machine learning parlance, a problem
of active learning). We show that recent work on methods for Bayesian
quadrature \cite{Diaconis:1988uo,OHagan:1991tx,Osborne:2012tm}
provides a way to solve this problem, outperforming several simpler
heuristics for determining both the direction and extent of rotation.

The plan of the paper is as follows. First, we give a brief overview
of the work on mental rotation and active learning. Next, we present
the problem domain and a computational-level analysis of how to solve
it. We describe three different models which approximate this
solution, evaluate their accuracy at approximating the computational
solution, and qualitatively compare their behavior to that of the
classic mental rotation results. We end with a discussion of the
strengths and weaknesses of each model, as well as directions for
future work.


\section{Background}

There is a long and rich history of work on mental rotation beginning
with Shepard and Metzler \cite{Shepard1971}, who presented
participants with pairs of images such as those shown in Figure
\ref{fig:mental-rotation} (left panel). These pairs of
three-dimensional objects could either be: the same object rotated in
plane (Figure \ref{fig:mental-rotation}A), the same object rotated in
depth (Figure \ref{fig:mental-rotation}B), or two different objects
(Figure \ref{fig:mental-rotation}C; in this case, the ``different''
objects had reflective symmetry, but no rotational
symmetry). Participants had to determine whether the two images were
of the same object or not, and \cite{Shepard1971} famously found that
response times for plane and depth rotations had a strong linear
relationship with the minimum angle of rotation between the two
objects (Figure \ref{fig:mental-rotation}, right panel). The
conclusion was that participants were visually ``rotating'' the
objects in their minds.

For many years, this idea was contested, with some researchers arguing
the underlying cognitive processes were not visual in nature
(e.g. \cite{Pylyshyn1981}). In particular, \cite{Anderson1978} proved
that the mental imagery debate could not be resolved on the basis of
response time data alone. In recent years, however, a significant
amount of work has investigated the neural underpinnings of the mental
rotation phenomena, arguing that the results of brain imaging studies
support the existence of visual mental rotation \cite{Kosslyn1988,
  Kosslyn:2009tj}.

We assume that mental imagery is indeed a visual process, and turn to
the question of how, and when, it is used. Previous work has examined
how people might use imagery \cite{Hegarty2004, Schwartz1999} to solve
reasoning problems, and when they might use imagery as opposed to a
symbolic rule \cite{Schwartz:1996uy}. Eye-tracking studies of people
performing mental rotations suggest strategies that people might be
using, such as aligning smaller features of the images
\cite{Just1976}. People seem to use imagery methodically, which raises
the question: what is the method?

Others studying people's pattern of behavior when engaged in
self-directed learning have found that they tend to use a strategy of
\textit{active learning} \cite{Gureckis:2012gu, Markant:2012uu}. When
given a choice as to the information they can obtain, people will not
choose the information randomly (as is the case with a \naive{} Monte
Carlo sampler), but according to some utility function such as
information gain \cite{Nelson2007, Markant:2012uu}. We propose that
such a strategy can be combined with the notion of mental imagery as a
tool: an optimal model of mental rotation may, perhaps, rely on an
active strategy. In the next sections, we investigate this idea with
several different approaches.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.95\textwidth]{../figures/shepard-rotation.png}
  \caption{\textbf{Classic mental rotation task}. Participants in
    \cite{Shepard1971} saw stimuli such as these, and judged whether
    each pair of shapes was the same shape in two different
    orientations, or two different shapes. \textbf{A} shows a ``plane
    rotation'', \textbf{B} shows a ``depth rotation'', and \textbf{C}
    shows two distinct objects. \TODO{update this caption}}
  \label{fig:mental-rotation}
\end{figure}

\section{Computational-level model}

We begin by first analyzing mental rotation at Marr's
\textit{computational} level \cite{Marr:1983to}: what is the problem
to be solved, and what is the optimal way to do so?  Formally, people
are presented with two images, $X_a$ and $X_b$, which are the
coordinates of the vertices of two-dimensional shapes similar to those
used by \cite{Cooper:1975wp} (e.g. Figure
\ref{fig:stimuli}). Participants must determine whether $X_a$ and
$X_b$ were generated from the same (albeit possibly transformed and
permuted) original shape, i.e., whether $\exists R,M\textrm{ s.t. }
X_b=MRX_a$, where $M$ is a permutation matrix and $R$ is a rotation
matrix.

We can formulate the judgment of whether $X_a$ and $X_b$ have the same
origins by deciding about two hypotheses, $h_0$: $\forall M,R\ X_b\neq
MRX_a$ and $h_1$: $\exists M,R\textrm{ s.t. } X_b=MRX_a$.  To compare
the hypotheses, we need to compute the posterior for each:
\begin{equation}
p(h\ \vert\ X_a, X_b)\propto p(X_a, X_b\ \vert\ h)p(h).
\end{equation}
Assuming the hypotheses are equally likely \textit{a priori}, the
prior term $p(h)$ will cancel out when comparing $h_0$ and $h_1$, thus
allowing us to focus on the likelihoods:
\begin{align}
  p(X_a,\ X_b\ \vert \ h_0)&=p(X_a)p(X_b) \label{eq:lh-h0}\\
  p(X_a,\ X_b\ \vert \ h_1)&=\int_R\int_M p(X_a) p(X_b\vert X_a,R,M) p(R) p(M)\ \mathrm{d}M\ \mathrm{d}R. \label{eq:lh-h1}
\end{align}
Under $h_0$, the likelihood is easy to compute because we assume that
$X_a$ and $X_b$ are independent (Equation \ref{eq:lh-h0}). When the
configurations are the same, the likelihood becomes more complicated
(Equation \ref{eq:lh-h1}). For a small number of vertices, we can
compute the integral over $M$ by enumerating every possible mapping
between $X_a$ and $X_b$. After doing so, we obtain:
\begin{equation} 
  p(X_a,\ X_b\ \vert \ h_1)=\int_R p(X_a) p(X_b\vert X_a,R) p(R)\ \mathrm{d}R.
\end{equation}

Once we have computed both likelihoods, we compute their ratio:
\begin{equation}
  \ell=\frac{p(X_a, X_b\ \vert \ h_1)}{p(X_a, X_b\ \vert \ h_0)}=\frac{\int_R p(X_b\ \vert\ X_a, R)p(R)\ \mathrm{d}R}{p(X_b)}.
  \label{eq:lh-ratio}
\end{equation}
If $\ell<1$, then $h_0$ is the more likely hypothesis. If $\ell>1$,
then $h_1$ is the more likely hypothesis.

\section{Metacognitive algorithms}

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../figures/stimuli_shapes.pdf}
    \vspace{0pt}
    \caption{Example stimuli}
    \label{fig:stimuli}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../figures/likelihood_function.pdf}
    \caption{Likelihood function}
    \label{fig:likelihood}
  \end{subfigure}
  \caption{\textbf{Rotated shapes and their similarity.}  \textbf{(a)}
    An example stimulus in which the shapes differ only by a
    rotation. All stimuli consist of three to six vertices centered
    around the origin, and edges which create a closed loop from the
    vertices. \textbf{(b)} The approximate likelihood (similarity) of
    $X_b$ given $X_R$, where $X_R$ is a rotation of $X_a$ by the angle
    $R$. The true angle of rotation between $X_a$ and $X_b$ is at
    $\frac{2\pi}{3}$, corresponding to the global maximum in the
    likelihood function.}
  \label{fig:shapes}
\end{figure}

Given the computational model defined above, we now explore the ways
in which it can be expressed algorithmically. First, we define the
prior probabilities over stimuli according to a generative
procedure. A set of $n$ vertices could be chosen in any of $n!$
different ways, and each vertex is located at a random angle (between
0 and $2\pi$) and radius (between 0 and 1). Thus, the prior over a
shape $X$ is $p(X)=n!\left(\frac{1}{2\pi}\right)^n$, which gives us
the denominator in Equation \ref{eq:lh-ratio}. Computing the numerator
is more difficult, as we we cannot compute $p(X_b\vert X_a, R)$
directly. Instead, we introduce a new variable $X_R$ denoting a mental
image, which approximates $RX_a$. The $X_R$ are generated by repeated
application of a function $\tau$:
\begin{align}
  X_R=RX_a&=\tau(X_{R-r}, r)=\tau(\tau(X_{R-2r}, r), r)=\ldots{}\nonumber \\
  &=\tau^{(\frac{R}{r})}(X_a, r).
  \label{eq:tau}
\end{align} 
where $r$ is a small angle, and $\tau^{(i)}$ indicates $i$ recursive
applications of $\tau$. Using this sequential function, we get:
\begin{align}
  p(X_a, X_b\ \vert \ h_1)&=\int_R \int_{X} p(X_b\vert X) p(X\vert X_a, R)p(X_a)p(R)\ \mathrm{d}X\ \mathrm{d}R \nonumber \\
  &= \int_R \int_X p(X_b\vert X)\delta(\tau^{(\frac{R}{r})}(X_a, r)-X)p(X_a)p(R)\ \mathrm{d}X\ \mathrm{d}R \nonumber \\
  &= \int_R p(X_b\vert X_R)p(X_a)p(R)\ \mathrm{d}R
\end{align}
However, the exact form of $p(X_b\vert X_R)$ is still unknown. We
approximate it with a similarity function $S(X_b, X_R)$, and denote
the resulting integral as $Z$:
\begin{equation}
Z=\int_R S(X_b, X_R)p(R)\ \mathrm{d}R\approx \int_R p(X_b\vert X_R)p(R)\ \mathrm{d}R.
\label{eq:Z}
\end{equation}
We define the similarity function $S$, which incorporates the
different mappings as vertices, as follows. Because the vertices are
connected in a way which forms a closed loop, we need only consider
$2n$ mappings of the $n$ vertices (we assume uncertainty for which is
the ``first'' vertex, and then which of its two neighbors is the
``second''). So, the possible orderings are of the form $M=\lbrace{}0,
1, \ldots{}, n\rbrace{}$, $M=\lbrace{}n, 0, \ldots{}, n-1\rbrace{}$,
and so on. Combining this with a Gaussian similarity metric, we
obtain:
\begin{equation}
  S(X_b, X_R)=\frac{1}{2n}\sum_{M\in\mathbb{M}}\prod_{i=1}^n\mathcal{N}(X_b[i]\ \vert \ (MX_R)[i], \Sigma)
  \label{eq:similarity}
\end{equation}
where $i$ denotes the $i^{th}$ vertex. An example stimulus and
corresponding $S$ is shown in Figure \ref{fig:shapes}.

To summarize, the process of generating a mental image consists of
computing a single $X_R$ (as in Equation \ref{eq:tau}) and then
computing $S(X_b, X_R)$. We denote the sequence of rotations computed
by this procedure as $\mathbf{R}=\{R_1, R_2, \ldots{}\}$. However,
this sequence cannot be arbitrary, as mental rotation is
computationally demanding. Our goal is to minimize the number of
rotations $\vert\mathbf{R}\vert$ while still obtaining an estimate of
$Z$ that is accurate enough to choose the correct hypothesis. With
this in mind, we now examine several approaches to solve this problem.

\paragraph{Gold standard}

To compare the accuracy of other models' estimates of $Z$, we computed
a ``gold standard'' by evaluating $S(X_b, X_R)$ at 360 values of $R$
spaced evenly between $0$ and $2\pi$ and estimating the integral using
the trapezoidal rule.

\paragraph{\Naive{}}

\begin{figure}[t]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../figures/li_regression.pdf}
    \caption{\Naive{} model}
    \label{fig:li}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../figures/vm_regression.pdf}
    \caption{Parametric model}
    \label{fig:vm}
  \end{subfigure}
  \caption{\textbf{Simple methods of estimating $S$.} In both cases,
    hill-climbing search is used until a maxima is found (in this
    case, at approximately $\frac{\pi}{6}$). The sampled points
    $\mathbf{R}$ (red circles) are then used to estimate $S$ (black
    lines are the true $S$, red lines are the estimate). \textbf{(a)}
    Linear interpolation. The overall estimate of $Z$ here will be too
    low, but certain angles will have a disproportionate contribution
    (e.g. between $\frac{\pi}{4}$ and $\frac{3\pi}{4}$. \textbf{(b)}
    Best fit of scaled Von Mises PDF parameters. As in (a), $Z$ will
    be underestimated. However, the fit around the maximum near
    $\frac{\pi}{6}$ is much more accurate.}
  \label{fig:simple-models}
\end{figure}

As a baseline, we defined a \naive{} model which performs a
hill-climbing search over the similarity function until it reaches a
(possibly local) maximum. Once a maximum as been found, the model
computes an estimate of $Z$ by linearly interpolating between sampled
rotations. Figure \ref{fig:li} shows an example of the \naive{}
model's estimate of $S$.

\paragraph{Parametric (Von Mises)}

Another strategy is to assume a parametric shape for $S$ and fit the
appropriate parameters. If we assume that $S$ is approximately
unimodal when $h_1$ is true\footnote{This is not always a reasonable
  assumption, see e.g. Figure \ref{fig:vm}.}, then a reasonable form
for the similarity function is that of a ``circular Gaussian'' or Von
Mises distribution:
\begin{equation}
  S(X_b, X_R) \approx h\cdot{}p(R\ \vert\ \hat{\theta}, \kappa)=\frac{h}{2\pi I_0(\kappa)}e^{\kappa\cos(R-\hat{\theta})}
\end{equation}
where $\kappa$ is the concentration parameter, $\hat{\theta}$ is the
preferred direction, $h$ is a scale parameter, and $I_0$ is the
modified Bessel function of order zero. We fit these parameters by
minimizing the mean squared error between this PDF and the computed
values of $S$. To choose the sequence of rotations, we use the same
hill-climbing strategy as in the \naive{} model. Figure \ref{fig:vm}
shows an example of the parametric model's estimate of $S$. 

\paragraph{Nonparametric (Bayesian Quadrature)}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{../figures/bq_regression.pdf}
  \caption{\textbf{Nonparametric model.} Each panel shows one step of
    the Bayesian Quadrature regression. Upper left: the original
    Gaussian Process (GP) regression for $S$. Lower left: the GP
    regression for $\log(S+1)$. Lower right: the GP regression for
    $\Delta_c=\mu_{\log S} - \log \mu_S$. Upper right: the adjusted
    regression for $S$, where the mean is equal to
    $\mu_S(1+\mu_{\Delta_c})$. The model uses this final estimate to
    compute $Z$ and will continue rotating until the variance of $Z$
    is low enough that a hypothesis may be accepted. This method
    allows the model to avoid local maxima such as the one near
    $\frac{\pi}{6}$, which causes trouble for the \naive{} and
    parametric models in Figure \ref{fig:simple-models}.}
  \label{fig:bq}
\end{figure}

A more flexible strategy uses what is known as \emph{Bayesian
  Quadrature} \cite{Diaconis:1988uo,OHagan:1991tx} to estimate $Z$.
Bayesian Quadrature allows us to compute a posterior distribution over
$Z$ by placing a Gaussian Process (GP) prior on the function $S$ and
evaluating $S$ at a particular set of points. Because our data is
circular, we use a periodic kernel \cite{Rasmussen:2006vz}:
\begin{equation}
k(R, R^\prime)=h^2\exp\left(-\frac{2\sin^2\left(\frac{1}{2}(R-R^\prime)\right)}{w^2}\right).
\end{equation}

Bayesian Quadrature has its difficulties, however. While in our case
$S$ is a non-negative likelihood function, GP regression enforces no
such constraint. In an effort to avoid this problem,
\cite{Osborne:2012tm} give a method to place a prior over the log
likelihood\footnote{In practice, as in \cite{Osborne:2012tm}, we use
  the transform of $\log(S+1)$. Additionally, we follow
  \cite{Osborne:2012tm} and use a combination of MLII and
  marginalization to fit the $w$ kernel parameters. The output scales
  are fixed at $h_S=\sqrt{0.1}$ and $h_{\log S}=\log(h_S + 1)$.}, thus
ensuring that $S=e^{\log S}$ will be positive\footnote{We are not
  guaranteed positivity, however, the approximation to the integral
  over $\log S$ (Equation \ref{eq:bq-Z-mean}) requires computing
  $\mu_S$, which may have non-positive segments.}:
\begin{equation*}
  E[Z\ \vert \ \log S]=\int_{\log S}\left(\int_R \exp(\log{S(X_b,X_R)})p(R)\ \mathrm{d}R\right)\mathcal{N}\left(\log{S}\ \vert \ \mu_{\log S}, \Sigma_{\log S}\right)\ \mathrm{d}\log S
\end{equation*}
where $\mu_{\log S}$ and $\Sigma_{\log S}$ are the mean and
covariance, respectively, of the GP regression over $\log S$ given
$\mathbf{R}$. We approximate this according to the method given in
\cite{Osborne:2012tm}:
\begin{equation}
  \mu_Z=E[Z\ \vert \ S, \log S, \Delta_c] \approx \int_R \mu_{S}(1 + \mu_{\Delta_c}) p(R)\ \mathrm{d}R 
  \label{eq:bq-Z-mean}
\end{equation}
where $\mu_S$ is the mean of a GP regression over $S$ given
$\mathbf{R}$; and $\mu_{\Delta_c}$ is a regression over
$\Delta_c=\mu_{\log S} - \log \mu_S$ given $\mathbf{R}_c$, which
consists of $\mathbf{R}$ and a set of intermediate \emph{candidate
  points} $c$ as described in \cite{Osborne:2012tm}. The variance is
$\tilde{V}(Z\vert S, \log S, \Delta_c)$ as defined in Equation 12 of
\cite{Osborne:2012tm}.

To start, we pick an initial direction of rotation which results in
the higher value of $S$. At each step, we compute $\mu_Z$ and
$\tilde{V}$ in order to estimate a distribution over the likelihood
ratio $\ell$:
\begin{equation*}
p(\ell)\approx\frac{1}{p(X_b)}\ \mathcal{N}(Z\ \vert\ \mu_Z, \sigma_z).
\end{equation*}
We choose $h_0$ when $p(\ell < 1)\geq 0.95$, and $h_1$ when $p(\ell >
1)\geq 0.95$. Until one of these conditions are met (or the shape has
been fully rotated), the model will continues to compute rotations and
update its estimate of $Z$. 

We additionally allow the model to change direction or ``reset'' based
on an estimate of the posterior variance of $Z$ given some new sample
$a$. This is similar to the procedure given in \cite{Osborne:2012tm},
however we do not compute the full posterior variance. Instead, we
compute the variance given only the current mean estimate of $a$. If
this estimated variance is lowered more by ``resetting'', then the
model will change directions. Thus, it is able to have an active say
in which mental rotations are computed, unlike the hill-climbing
procedure.

% \begin{equation}
%   \sigma_Z=\mathrm{Var}(Z\ \vert \ S, \log S, \Delta_c) = \int_R\int_{R^\prime} \mu_S(R)\mu_S(R^\prime) \Sigma_{\log S}(R, R^\prime)p(R)p(R^\prime)\ \mathrm{d}R\ \mathrm{d}R^\prime
%   \label{eq:bq-Z-var}
% \end{equation}

\section{Results}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{../figures/model_rotations.pdf}
  \caption{\textbf{Model rotations.} Top: each subplot shows the
    correspondence between the true angle of rotation ($R$) for
    ``same'' pairs and the amount of rotation performed by the
    model. Bottom: each subplot shows the models' mean rotations over
    stimuli pairs that were judged correctly. Black dots correspond to
    ``same'' pairs, and blue lines correspond to ``different'' pairs
    (for which the mean rotation is constant across true rotations, as
    the true rotation is undefined). Error bars/shaded regions
    indicate one standard deviation, and the dotted lines indicate the
    least-squares fit to the ``same'' pairs.}
  \label{fig:rotations}
\end{figure}

We evaluated each model's performance on 20 shapes which had between 3
and 6 vertices, inclusive, (e.g. $X_a$ in Figure
\ref{fig:stimuli}). For each shape, we computed 18 ``same'' and 18
``different'' stimuli pairs, with $R$ spaced at $20^\prime$ increments
between 0 and 360, as in \cite{Shepard1971}. ``Same'' pairs were
created by rotating $X_a$ by $R$; the same was true for ``different'',
except that $X_a$ was also reflected across the $y$-axis. Each shape
was generated randomly, but under the constraint that the
``same''/``different'' pairs created from the shape could both be
judged according to the ``gold standard''.

We considered three metrics of performance in particular:
\begin{itemize}
\item \textit{Response error rates}: How accurate was the model at
  choosing the correct hypothesis? This was defined to be the mean
  error ($\ME{}$), or fraction of times the model picks the incorrect
  hypothesis.
\item \textit{Rotations}: For those ``same'' pairs which the model
  judged correct, how correlated were the model's rotations with the
  true angles of rotation?  We quantified this using the Pearson's
  correlation coefficient $\rho$ for the true rotation ($R$) versus
  the extent of the model's rotations ($\vert \mathbf{R}\vert$). The
  top row in Figure \ref{fig:rotations} shows individual points
  corresponding to true rotations vs. rotations by the models for all
  stimuli, including those judged incorrectly. The bottom row shows
  mean model rotations, across only those stimuli which were judged
  correctly. We structured the analysis in this way to better compare
  to the results of \cite{Shepard1971}, which also excluded
  incorrectly judged stimuli.
\item \textit{Estimates of $Z$}: How accurate was the model's estimate
  of $Z$? We defined this quantity as the mean squared error
  ($\MSE{}$) between the model's estimate of $Z$ and the ``gold
  standard'' value, where the error has scale such that $\MSE{}=0$
  indicates no error and $\MSE{}=1$ indicates maximum error. Figure
  \ref{fig:accuracy} shows plots of the true (``gold standard'') value
  of $Z$ vs. the model's estimate, for each model.
\end{itemize}

\paragraph{\Naive{}} 

The \naive{} model's response error rate was $\NaiveME{}$, which is
better than chance (equivalent to guessing randomly,
i.e. $\ME{}=0.5$). \TODO{binomial test?} Closer inspection reveals
that much of this comes from ``different'' pairs ($\NaiveMEdiff{}$),
where the asymmetric linear interpolation may give an overestimate of
$Z$ (e.g. Figure \ref{fig:li}).  This intuition is confirmed by the
model's accuracy in estimating $Z$, which was $\NaiveMSE{}$. As shown
in the left panel of Figure \ref{fig:accuracy}, it overestimated $Z$
for nearly all stimuli pairs. \TODO{how many?}

The correlation between the \naive{} model's average rotation and the
true angle of rotation was $\Naivecorr{}$ (Figure \ref{fig:rotations},
bottom left). More complex patterns are revealed by examining the
shape of the raw data in Figure \ref{fig:rotations}, top left: the
\naive{} model corresponds extremeley well to the true angle of
rotation for approximately $R<\frac{\pi}{2}$. This is unsurprising,
because the closer the true angle is to zero, the less the model has
to rotate, and the less likely it will get stuck on local
maxima. Thus, it is more likely to locate the global maximum, which
corresponds to the true angle of rotation. For $R>\frac{\pi}{2}$, we
see an increasing tendency to under-rotate due to getting stuck on
local maxima, as well as a tendency to over-rotate if the wrong
direction was initially chosen.


\paragraph{Parametric (Von Mises)}

The parametric model's error in determining whether the objects were
identical was $\VMME{}$, making more errors on ``same'' pairs
($\VMMEsame{}$) than ``different'' pairs ($\VMMEdiff{}$). \TODO{is
  this significant?} Rather than overestimating as with the \naive{}
model, however, the parametric model largely underestimated $Z$. This
is unsurprising: because the Von Mises distribution only has a single
peak, it necessarily underestimates $Z$ for multimodal similarity
functions. Overall, the parametric model had an error rate of
$\VMMSE{}$ in estimating $Z$, which was significantly more accurate
than that of the \naive{} model \TODO{test}.

The correlation between the parametric model's average rotation and
the true angle of rotation was also higher ($\VMcorr{}$), though this
is because more of the underestimated stimuli pairs were excluded from
the analysis. The individual rotations performed by the parametric and
\naive{} models were actually identical (see Figure
\ref{fig:rotations}, upper left and center) because both models use
the same hill-climbing stopping strategy.


\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{../figures/Z_accuracy.pdf}
  \caption{\textbf{Accuracy in estimating $Z$.} Each subplot shows the
    true (``gold standard'') value of $Z$ vs. the value estimated by
    the model. Black dotted lines indicate a perfect 1:1
    correspondence between the true and estimated values. The \naive{}
    model (left panel) tends to overestimate. The parametric model
    (center panel) is very accurate for about half the ``same'' pairs,
    and severely underestimates the rest. The nonparametric model
    (right panel) maintains a decent correspondence with the true
    $Z$.}
  \label{fig:accuracy}
\end{figure}


\paragraph{Nonparametric (Bayesian Quadrature)}

The nonparametric model was much more accurate in choosing the correct
hypothesis than the other two models ($\BQME{}$) \TODO{test}. We note
that this is very close to the 3.2\% error rate reported by
\cite{Shepard1971}, though further experimentation is necessary to
determine whether the types of errors people make align with those of
the model.

The average rotations computed by the nonparametric model were
strongly correlated with the true rotations ($\BQcorr$, see Figure
\ref{fig:rotations}, bottom right). Because the nonparametric model
has the capacity to ``reset'', it could recover from rotating in the
incorrect direction (e.g. Figure \ref{fig:bq}) and thus did not
over-rotate as frequently.  It also under-rotated less frequently:
because the model continues to rotate until it is confident that its
estimate of $Z$ is accurate, it does not get stuck as easily on local
optima.  Indeed, its active attempts to obtain an accurate estimate of
$Z$ were largely succeessful, with $\BQMSE{}$.


\section{Discussion}

In this paper, we asked: how do people use mental simulation?  We
investigated the specific case of mental rotation, taking a rational
analysis approach to characterizing optimal strategies for performing
mental rotation. We found that an adaptive, nonparametric model
performs best at the classic rotation task \cite{Shepard1971}, as it
is able to actively monitor the confidence of its estimate and
intelligently choose the direction of rotation. Two simpler models
based on heuristics performed much worse: they did not maintain the
linear relationship with the true angle of rotation due to lack of
robustness against local maxima or incorrect rotation direction. The
nonparametric model qualitatively approximates human behavioral
judgments, both in linearity \cite{Shepard1971} and variability
\cite{Just1976}. Future work will collect empirical data from
participants to perform a more thorough, quantitative analysis.  We
conclude that from this initial survey, models of mental rotation
which take an ``active'', directed approach seem well-suited to
explaining human behavior in such metacognitive domains as mental
simulation.


% One option for improving the performance of the simple models would be
% to fit a threshold value, below which local maxima would be
% ignored. However, this strategy would be rather brittle, for if the
% distribution of shapes changed, the threshold would have to be
% re-learned. It is possible that people exhibit this behavior, but we
% cannot make any assumptions one way or the other without empirical
% data.

% A further strength of the nonparametric model over the other models,
% however, is that it is likely to generalize well to three
% dimensions. One aspect of \cite{Osborne:2012tm} which we have not yet
% explored is their main contribution of \textit{active sampling}, in
% which samples are iteratively selected to maximally decrease the
% expected variance of $Z$. Due to the sequential constraint of mental
% rotation, this strategy is not particularly useful in two dimensions,
% as there are only every two directions in which to rotate. In three
% dimensions, however, there are an infinite number of directions that
% could be chosen after every step.


% \textbf{Acknowledgments}
% \TODO{}


% \renewcommand\bibsection{\subsubsection*{\refname}}
\renewcommand\refname{\normalsize{References}}
\bibliographystyle{ieeetr}
\bibliography{references}

\end{document}



